{
  "docs": [
    {
      "id": 20269142,
      "title": "Ask HN: GitHub or Gitlab",
      "search": [
        "Ask HN: GitHub or Gitlab",
        "Migrating from an existing Git provider, curious what other folks have to say.<p>We're a building a SaaS app with no open source components at the moment.",
        "AskHN",
        "I have been enjoying Gitlab's built-in continuous integration service. If your app does not already use something else for continuous integration, it might be worthwhile to try out.",
        "We currently use Bitbucket (do not recommend) and we're evaluating GitLab.<p>First impression is that it's a great package. The only downside for us is that we have a lot of legacy baggage, mostly rather opinionated build tools set up the way we liked it. Getting that to work with GitLab, which itself has a very opinionated view of the CI/CD pipeline is a bit of effort. But for a greenfield project I would go with GitLab in a second!<p>GitLab is a \"batteries included\" kind of tool. They've put together a lot of excellent stuff and integrated different tools very well together. For example, we need to perform security scans on our code and artifacts and GitLab offers that with minimal effort and awesome integrations into your pull request (which they call merge requests) mechanism.<p>Some may not like their approach, especially if they already have something that doesn't quite fit. But if you're starting from scratch, you really should give them a chance. They really know what they're doing ;-)"
      ],
      "relevant": "true"
    },
    {
      "id": 20618427,
      "title": "Git-Revise",
      "search": [
        "Git-Revise",
        "Normal",
        "https://mystor.github.io/git-revise.html",
        "NIKA:\\git-revise\\> list (Aug. 6, 2019): Added the \"What git-revise is not\" section. At Mozilla I often end up building my changes in a patch stack, and used git rebase -i1 to make changes to commits in response to review comments etc. Unfortunately, with a repository as large as mozilla-central2, git rebase -i has some downsides: It's slow! Rebase operates directly on the worktree, so it performs a full checkout of each commit in the stack, and frequently refreshes worktree state. On large repositories (especially on NTFS) that can take a long time. It triggers rebuilds! Because rebase touches the file tree, some build systems (like gecko's recursive-make backend) rebuild unnecessarially. It's stateful! If the rebase fails, the repository is in a weird mid-rebase state, and in edge cases I've accidentally dropped commits due to other processes racing on the repository lock. It's clunky! Common tasks (like splitting & rewording commits) require multiple steps and are unintuitive. Naturally, I did the only reasonable thing: Build a brand-new tool. source: xkcd git-revise is a history editing tool designed for the patch-stack workflow. It's fast, non-destructive, and aims to provide a familiar, powerful, and easy to use re-imagining of the patch stack workflow. It's fast I would never claim to be a benchmarking expert 3, but git-revise performs substantially better than rebase for small history editing tasks 4. In a test applying a single-line change to a mozilla-central commit 20 patches up the stack I saw a 15x speed improvement. $ time bash -c 'git commit --fixup=$TARGET; EDITOR=true git rebase -i --autosquash $TARGET~' <snip> real 0m10.733s $ time git revise $TARGET <snip> real 0m0.685s git-revise accomplishes this using an in-memory rebase algorithm operating directly on git's trees, meaning it never has to touch your index or working directory, avoiding expensive disk I/O! It's handy git-revise isn't just a faster git rebase -i, it provides helpful commands, flags, and tools which make common changes faster, and easier: Fixup Fast $ git add . $ git revise HEAD~~ Running git revise $COMMIT directly collects changes staged in the index, and directly applies them to the specified commit. Conflicts are resolved interactively, and a warning will be shown if the final state of the tree is different from what you started with! With an extra -e, you can update the commit message at the same time, and -a will stage your changes, so you don't have to! 5 Split Commits $ git revise -c $COMMIT Select changes to be included in part [1]: diff --git b/file.txt a/file.txt <snip> Apply this hunk to index [y,n,q,a,d,e,?]? Sometimes, a commit needs to be split in two, perhaps because a change ended up in the wrong commit. The --cut flag (and cut interactive command) provides a fast way to split a commit in-place. Running git revise --cut $COMMIT will start a git add -p-style hunk selector, allowing you to pick changes for part 1, and the rest will end up in part 2. No more tinkering around with edit during a rebase to split off that comment you accidentally added to the wrong commit! Interactive Mode git-revise has a git rebase -i-style interactive mode, but with some quality-of-life improvements, on top of being fast: Implicit Base Commit If a base commit isn't provided, --interactive will implicitly locate a safe base commit to start from, walking up from HEAD, and stopping at published & merge commits. Often git revise -i is all you need! The index Todo Staged changes in the index automatically appear in interactive mode, and can be moved around and treated like any other commit in range. No need to turn it into a commit with a dummy name before you pop open interactive mode & squash it into another commit! Bulk Commit Rewording Ever wanted to update a bunch of commit messages at once? Perhaps they're all missing the bug number? Well, git revise -ie has you covered. It'll open a special Interactive Mode where each command is prefixed with a ++, and the full commit message is present after it. Changes made to these commit messages will be applied before executing the TODOs, meaning you can edit them in bulk. I use this constantly to add bug numbers, elaborate on commit details, and add reviewer information to commit messages. ++ pick f5a02a16731a Bug ??? - My commit summary, r=? The full commit message body follows! ++ pick fef1aeddd6fb Bug ??? - Another commit, r=? Another commit's body! Autosquash Support $ git revise --autosquash If you're used to git rebase -i --autosquash, revise works with you. Running git revise --autosquash will automatically reorder and apply fixup commits created with git commit --fixup=$COMMIT and similar tools, and thanks to the implicit base commit, you don't even need to specify it. You can even pass the -i flag if you want to edit the generated todo list before running it. It's non-destructive git-revise doesn't touch either your working directory, or your index. This means that if it's killed while running, your repository won't be changed, and you can't end up in a mid-rebase state while using it. Problems like conflicts are resolved interactively, while the command is running, without changing the actual files you've been working on. And, as no files are touched, git-revise won't trigger any unnecessary rebuilds! What git-revise is not (Section Added: Aug. 6, 2019) git-revise does not aim to be a complete replacement for git rebase -i. It has a specific use-case in mind, namely incremental changes to a patch stack, and excludes features which rebase supports. In my personal workflow, I still reach for git rebase [-i] when I need to rebase my local commits due to new upstream changes, and I imagine there are people with advanced workflows who cannot use git revise. Working directory changes: git-revise does not modify your working directory or index while it's running. This is part of what allows it to be so fast. However, it also means that certain rebase features, such as the edit interactive command, are not possible. This also is why git revise -i does not support removing commits from within a patch series: doing so would require changing the state of your working directory due to the now-missing commit. If you want to drop a commit you can instead move it to the end of the list and mark it as index. The commit will disappear from history, but your index and working directory won't be changed. A quick git reset --hard HEAD will update your index and working directory. These restrictions may change in the future. Features like this have been requested, and it might be useful to allow opting-in to dropping commits on the floor or pausing mid-revise. Merging through renames & copies: git-revise uses a custom merge backend, which doesn't attempt to handle file renames or copies. For changes which need to be merged or rebased through file renames and copies, git rebase is a better option. Complex history rewriting: git rebase supports rebasing complex commits, such as merges. In contrast, git-revise does not currently aim to support these more advanced features of git rebase. Interested? Awesome! git-revise is a MIT-licensed pure-Python 3.6+ package, and can be installed with pip: $ python3 -m pip install --user git-revise You can also check out the source on GitHub, and read the manpage online, or by running man git revise in your terminal. I'll leave you with some handy links to resources to learn more about git-revise, how it works, and how you can contribute! Repository: https://github.com/mystor/git-revise Bug Tracker: https://github.com/mystor/git-revise/issues Manpage: https://git-revise.readthedocs.io/en/latest/man.html Installing: https://git-revise.readthedocs.io/en/latest/install.html Contributing: https://git-revise.readthedocs.io/en/latest/contributing.html ",
        "Reminds me some of Raymond Chen's \"Stupid Git Tricks\" series  [0-6] of blog posts where he used a lot of git commit-tree and similar low level tools to avoid worktree changes and minimize GC churn (partly because of working in the humongous Windows git, which of course seems to have similar issues to the Mozilla ones mentioned here such as auto-rebuild tools).<p>It makes a bunch of sense to build nicer porcelain tools for such low level git magic when it becomes semi-routine.<p>(I couldn't find a good permalink for the entire series as a whole, so linked are all the individual posts.)<p>[0] <a href=\"https://devblogs.microsoft.com/oldnewthing/20190506-00/?p=102478\" rel=\"nofollow\">https://devblogs.microsoft.com/oldnewthing/20190506-00/?p=10...</a><p>[1] <a href=\"https://devblogs.microsoft.com/oldnewthing/20190507-00/?p=102480\" rel=\"nofollow\">https://devblogs.microsoft.com/oldnewthing/20190507-00/?p=10...</a><p>[2] <a href=\"https://devblogs.microsoft.com/oldnewthing/20190508-00/?p=102482\" rel=\"nofollow\">https://devblogs.microsoft.com/oldnewthing/20190508-00/?p=10...</a><p>[3] <a href=\"https://devblogs.microsoft.com/oldnewthing/20190509-00/?p=102485\" rel=\"nofollow\">https://devblogs.microsoft.com/oldnewthing/20190509-00/?p=10...</a><p>[4] <a href=\"https://devblogs.microsoft.com/oldnewthing/20190510-00/?p=102488\" rel=\"nofollow\">https://devblogs.microsoft.com/oldnewthing/20190510-00/?p=10...</a><p>[5] <a href=\"https://devblogs.microsoft.com/oldnewthing/20190513-00/?p=102490\" rel=\"nofollow\">https://devblogs.microsoft.com/oldnewthing/20190513-00/?p=10...</a><p>[6] <a href=\"https://devblogs.microsoft.com/oldnewthing/20190515-00/?p=102495\" rel=\"nofollow\">https://devblogs.microsoft.com/oldnewthing/20190515-00/?p=10...</a>",
        "This sounds exactly like my dream tool, the very thing I've been meaning to write myself and haven't gotten around to it. Thank you for writing this!<p>Suggestion: I'd love to see a `revise.autoSquash` git config flag (like `rebase.autoSquash`) to always autosquash in interactive mode. Maybe you already support it, but if so, the manpage doesn't list it."
      ],
      "relevant": "true"
    },
    {
      "id": 19276542,
      "title": "Bitbucket Pipes",
      "search": [
        "Bitbucket Pipes",
        "Normal",
        "https://bitbucket.org/blog/meet-bitbucket-pipes-30-ways-to-automate-your-ci-cd-pipeline",
        "The democratizing nature of DevOps has seen the responsibility of building and managing CI/CD pipelines transition from specialized release engineers to developers. But automating a robust, dependable CI/CD pipelineistedious work. Developers need to connect to multiple tools to deliver software, andwriting pipeline integrations for these servicesis a manual, error-prone process. Theres research involved to ensure dependencies are accounted for, as well as debugging and maintainingintegrationswhen updates are made. Its no wonder many teams put automating CI/CD firmly in the too hard basket. But those days are over. In 2016 we launched Bitbucket Pipelines: a CI/CD tool in the cloud that's part of your repository and makes it easy for developers to configure pipelines with code.Andtoday we are launching Bitbucket Pipes to make it easier to build powerful, automated CI/CD workflows in a plug and play fashion without the hassle ofmanaging integrations.Weve worked with industry leaders including Microsoft, AWS, Slack, Google Cloud and more to build supported pipes that help automate your CI/CD pipeline, and made it simple to create your own to help abstract any duplicated configuration across your repositories. Announcing Bitbucket Pipes Whether youre creating a simple deploy pipeline to a hosting service like AWS, utilizing a multi-cloud deployment strategy, or automating a sophisticated pipeline that involves security scanning, monitoring, and artifact management, Bitbucket Pipes makes it easy to build and automate a CI/CD pipeline that meets your exact needs. Simply select the appropriate pipes you need and enter in the variables required by the pipe to run. Not only do supported pipes make it trivial to set up your external services across pipelines and repositories, theyre also updated and maintained by the author meaning you never have to worry about updating or re-configuring them yourself. The end result is an easy way to build, update, modify, and maintain CI/CD pipelines no matter how sophisticated they are. In the example below you can see how easy configuring your pipeline becomes by simply copying and pasting pipes on the right, versus manually typing and configuring the same pipeline on the left. New users can easily browse and select pipes to get started, while more experienced users can not only reuse pipes across their repositories, but discover new and interesting ways to automate their pipelines. An open approach to automation Theres no one-size-fits-all approach to software development ? developers should work with whatever tools best suit their needs. Whether its hosting, monitoring, incident management and everything in-between, weve partnered with some of the best in the industry to bring the tools you already use right into your CI/CD pipeline. These partners are just scratching the surface for Bitbucket Pipes and we have more supported pipes to come. And we want the community involved too ? tell us which services youd like to see or even build your own. Its easy to build pipes that meet your exact needs and we cant wait to see how your team automates your CI/CD workflow. Get started with Bitbucket Pipes Get started with our pre-configured pipes or create your own today. For those new to Bitbucket, sign up, create your first repository and enable Bitbucket Pipelines. For existing Bitbucket Pipelines users, you can find the new Pipes view in the online .yml editor. Read our docs to find out more. ",
        "Free tier(Build minutes: 50 mins/mo)<p>Thanks but no thank you, meanwhile GitLab offers 2000 mins/mo",
        "Seems somewhat similar to resources[0] in Concourse in that they use a container image that has a defined entry point.<p>Concourse refers to this as a \"get step\"[1] or a \"put step\", which calls a pre-defined script inside the container with a custom set of parameters. The \"put step\" is used when you expect side effects, while a \"get step\" is used to check status on some resource and trigger jobs.<p>In general it makes the CI/CD system easily composable and clean. Concourse manages this very well and while I haven't used Bitbucket Pipes I suspect it to be a good experience as well.<p>[0] <a href=\"https://concourse-ci.org/resources.html\" rel=\"nofollow\">https://concourse-ci.org/resources.html</a>\n[1] <a href=\"https://concourse-ci.org/implementing-resources.html\" rel=\"nofollow\">https://concourse-ci.org/implementing-resources.html</a>"
      ],
      "relevant": "true"
    },
    {
      "id": 19989684,
      "title": "GitHub Sponsors",
      "search": [
        "GitHub Sponsors",
        "Normal",
        "https://github.com/sponsors",
        "GitHub Sponsors Invest in the software that powers your world A new way to contribute to opensource Invest in the open source projects you depend on. Contributors are working behind the scenes to make open source better for everyonegive them the help and recognition they deserve. Open source is an integral component of Stripes software supply chain, providing distribution that meets our users where they are and extending our platform to its fullest potential. Mike Fix, OSS lead & Software Engineer, Stripe Invest in your supply chain Sponsor the open source software your team has built its business on. Fund the projects that make up your software supply chain to improve its performance, reliability, and stability. Sponsor a project At New Relic developers are at the heart of everything we do, and that includes investing in the growth of a thriving open source community. Jonan Scheffler, Director of Developer Relations, New Relic You depend on open source every day A command line tool and library for transferring data with URL syntax, supporting HTTP, HTTPS, FTP, FTPS 18,600 4,000 Sponsor cURL is included in almost every modern devicesmartphones, cars, TVs, laptops, servers, gaming consoles, printers, and beyond. 10,000,000,000+ Installations of cURL worldwide 643 Community contributors 8 Maintainers TLS/SSL and crypto library 14,100 6,300 Sponsor OpenSSL is used to encrypt an estimated 66% of the web, including popular sites like Facebook, Google, and Netflix. 1,320,000,000+ Websites use OpenSSL worldwide 519 Community contributors 18 Maintainers Make open source careers possible Everyone should be able to afford to contribute to open source. Help make open source a viable, lucrative career path for people to create and contribute to our digital infrastructure. Sponsor in three easy steps Visit the projects sponsorship page. Choose a subscription tier. Pay! Explore the projects you depend on @katmeisters goal is to dedicate more time to opensource $15,000 a month When I reach this goal, Ill be able to quit my day job and work on open source full-time. 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 % towards $15,000 goal GitHub Sponsors could eventually lead to a better world where an open source maintainer generates enough income to bring on a second maintainer. David Nolen, Maintainer of Clojurescript Available in 36 regions Join the waitlist to receive updates when we expand. Anyone can sponsor, but you must reside in a supported region to receive funds. Australia Austria Belgium Bulgaria New Canada Cyprus Czech Republic Denmark Estonia Finland France Germany Greece Hong Kong SAR Ireland Italy Japan Latvia Lithuania Luxembourg Malta Mexico Netherlands New Zealand Norway Poland Portugal Romania New Singapore Slovakia Slovenia Spain Sweden Switzerland United Kingdom United States of America Frequently asked questions When can I get off the waitlist to join GitHub Sponsors? If youre in a supported country or region, you can join the program immediately. If youre in an unsupported country or region, join the waitlist for updates on availability in your location. While we cant provide an estimated timeframe, were growing all the time! Do I need to fill out a tax form to receive sponsorships? Yes, your tax information must be on file in order for GitHub to make payments to your bank account. Tax documents collected may vary based on your location. Note that we do our best to help you with the Sponsors program, but were unable to provide you with tax guidance. How do I sponsor a project? If your organization pays via credit card or PayPal, you can join the beta and start sponsoring right away. For organizations with invoiced billing, contact us. Invest in the projects youdepend on Invest in the projects you depend on ",
        "This seems like it's needed and (dareisay) overdue?<p>Integrating sponsorship subscriptions into the core experience is sure to increase payments, a la twitch subscriptions/payments (which Youtube is just now copying).<p>I imagine this will change the fundamental dynamics around OSS projects, but not sure how, nor whether it is all positive.<p>- If maintainers can see who donated, do they prioritize issues / pull requests? (I think that could be a good thing actually).<p>- Do companies use GitHub sponsorships to judge the health of dependencies? Will they create budgets to support their dependencies systematically?<p>- Does this hurt FOSS contributions, because now people start to expect to be paid rather than doing it for inherent motivations? Will this generate toxic politics among project contributors regarding who gets credit + gets paid?<p>- Will this mean that microsoft gets a bunch of PII on top-notch developers (have to enter name + address info to receive or send payments), and get much more value from that data than I can imagine?",
        "This is a nice start for allowing sending \"coffee money\" between persons. If however you want to drive Serious Money into actually funding OSS projects please remember this: While virtually no company has a donations budget, almost every company has a $$$ marketing budget.<p>Please let me give you some of that money that would otherwise be spent on blue pens with logos and endless display ads to GitHub projects. I'd be happy to drive $xxK/mo to open source projects my company depends on or that are simply being used by an audience that aligns with our own. To sell that internally, I need (as in, I would be laughed out of the room to propose it without):<p>- My sponsoring company logo on the GitHub project page<p>- UTM links and all that jazz to attribute traffic and campaigns to the specific projects that we sponsor<p>See <a href=\"https://webpack.js.org/\" rel=\"nofollow\">https://webpack.js.org/</a> for a good example of a successful sponsorship program. Literally the biggest hurdle remaining for BigCorp to sponsor something like Webpack today is selling your boss on \"Patreon\" and \"OpenCollective\". But if you just increase our GitHub budget by a few K/month, AND the marketers get attributable traffic to boot that we can point to, well that's an easy sell!"
      ],
      "relevant": "true"
    },
    {
      "id": 19240168,
      "title": "Git 2.21 Highlights",
      "search": [
        "Git 2.21 Highlights",
        "Normal",
        "https://github.blog/2019-02-24-highlights-from-git-2-21/",
        "The open source Git project just released Git 2.21 with features and bug fixes from over 60 contributors. We last caught up with you on the latest Git releases when 2.19 was released. Heres a look at some of the most interesting features and changes introduced since then. Human-readable dates with --date=human As part of its output, git log displays the date each commit was authored. Without making an alternate selection, timestamps will display in Gits default format (for example, Tue Feb 12 09:00:33 2019 -0800). Thats very precise, but a lot of those details are things that you might already know, or dont care about. For example, if the commit happened today, you already know what year it is. Likewise, if a commit happened seven years ago, you dont care which second it was authored. So what do you do? You could use --date=relative, which would give you output like 6 days ago, but often, you want to relate six days ago to a specific event, like my meeting last Wednesday. So, was six days ago Tuesday, or was it Wednesday that you were interested in? Git 2.21 introduces a new date format that tells you exactly when something occurred with just the right amount of detail: --date=human. Heres how git log looks with the new format: Thats both more accurate than --date=relative and easier to consume than the full weight of --date=default. But what about when youre scripting? Here, you might want to frequently switch between the human and machine-readable formats while putting together a pipeline. Git 2.21 has an option suitable for this setting, too: --date=auto:human. When printing output to a pager, if Git is given this option it will act as if it had been passed --date=human. When otherwise printing output to a non-pager, Git will act as if no format had been given at all. If human isnt quite your speed, you can combine auto with any other format of your choosing, like --date=auto:relative. [source] Detecting case-insensitive path collisions One commonly asked Git question is, After cloning a repository, why does git status report some of the files as modified? Quite often, the answer is that the repository contains a tree which cannot be represented on your file system. For instance, if it contains both file as well as FILE and your file system is case-insensitive, Git can only checkout one of those files. Worse, Git doesnt actually detect this case during the clone; it simply writes out each path, unaware that the file system considers them to be the same file. You only find out something has gone wrong when you see a mystery modification. The exact rules for when this occurs will vary from system to system. In addition to folding what we normally consider upper and lowercase characters in English, you may also see this from language-specific conversions, non-printing characters, or Unicode normalization. In Git 2.20, git clone now detects and reports colliding groups during the initial checkout, which should remove some of the confusion. Unfortunately, Git cant actually fix the problem for you. What the original committer put in the repository cant be checked out as-is on your file system. So if youre thinking about putting files into a multi-platform project that differ only in case, the best advice is still: dont. [source] Performance improvements and other bits Behind the scenes, a lot has changed over the last couple of Git releases, too. Were dedicating this section to overview a few of these changes. Not all of them will impact your Git usage day-to-day, but some will, and all of the changes are especially important for server administrators. Multi-pack indexes Git stores objects (e.g., representations of the files, directories, and more that make up your Git repository) in both the loose and packed formats. A loose object is a compressed encoding of an object, stored in a file. A packed object is stored in a packfile, which is a collection of objects, written in terms of deltas of one another. Because it can be costly to rewrite these packs every time a new object is added to the repository, repositories tend to accumulate many loose objects or individual packs over time. Eventually, these are reconciled during a repack operation. However, this reconciliation is not possible for larger repositories, like the Windows repository. Instead of repacking, Git can now create a multi-pack index file, which is a listing of objects residing in multiple packs, removing the need to perform expensive repacks (in many cases). [source] Delta islands An important optimization for Git servers is that the format for transmitted objects is the same as the heavily-compressed on-disk packfiles. That means that in many cases, Git can serve repositories to clients by simply copying bytes off disk without having to inflate individual objects. But sometimes this assumption breaks down. Objects on disk may be stored as deltas against one another. When two versions of a file have similar content, we might store the full contents of one version (the base), but only the differences against the base for the other version. This creates a complication when serving a fetch. If object A is stored as a delta against object B, we can only send the client our on-disk version of A if we are also sending them B (or if we know they already have B). Otherwise, we have to reconstruct the full contents of A and re-compress it. This happens rarely in many repositories where clients clone all of the objects stored by the server. But it can be quite common when multiple distinct but overlapping sets of objects are stored in the same packfile (for example, due to repository forks or unmerged pull requests). Git may store a delta between objects found only in two different forks. When someone clones one of the forks, they want only one of the objects, and we have to discard the delta. Git 2.20 solves this by introducing the concept of delta islands. Repository administrators can partition the ref namespace into distinct islands, and Git will avoid making deltas between islands. The end result is a repository which is slightly larger on disk but is still able to serve client fetches much more cheaply. [source 1, source 2] Delta reuse with bitmaps We already discussed the importance of reusing on-disk deltas when serving fetches, but how do we know when the other side has the base object they need to use the delta we send them? If were sending them the base, too, then the answer is easy. But if were not, how do we know if they have it? That answer is deceptively simple: the client will have already told us which commits it has (so that we dont bother sending them again). If they claim to have a commit which contains the base object, then we can re-use the delta. But theres one hitch: we not only need to know about the commit they mentioned, but also the entire object graph. The base may have been part of a commit hundreds or thousands of commits deep in the history of the project. Git doesnt traverse the entire object graph to check for possible bases because its too expensive to do so. For instance, walking the entire graph of a Linux kernel takes roughly 30 seconds. Fortunately, theres already a solution within Git: reachability bitmaps. Git has an optional on-disk data structure to record the sets of objects reachable from each commit. When this data is available, we can query it to quickly determine whether the client has a base object. This results in the server generating smaller packs that are produced more quickly for an overall faster fetch experience. [source] Custom alternates reference advertisement Repository alternates are a tool that server administrators have at their disposal to reduce redundant information. When two repositories are known to share objects (like a fork and its parent), the fork can list the parent as an alternate, and any objects the fork doesnt have itself, it can look for in its parent. This is helpful since we can avoid storing twice the vast number of objects shared between the fork and parent. Likewise, a repository with alternates advertises tips it has when receiving a push. In other words, before writing from your computer to a remote, that remote will tell you what the tips of its branches are, so you can determine information that is already known by the remote, and therefore use less bandwidth. When a repository has alternates, the tips advertisement is the union of all local and alternate branch tips. But what happens when computing the tips of an alternate is more expensive than a client sending redundant data? It makes the push so slow that we have disabled this feature for years at GitHub. In Git 2.20, repositories can hook into the way that they enumerate alternate tips, and make the corresponding transaction much faster. [source] Tidbits Now that weve highlighted a handful of the changes in the past two releases, we want to share a summary of a few other interesting changes. As always, you can learn more by clicking the source link, or reading the documentation or release notes. Have you ever tried to run git cherry-pick on a merge commit only to have it fail? You might have found that the fix involves passing -m1 and moved on. In fact, -m1 says to select the first parent as the mainline, and it replays the relevant commits. Prior to Git 2.21, passing this option on a non-merge commit caused an error, but now it transparently does what you meant. [source] Veteran Git users from our last post might recall that git branch -l establishes a reflog for a newly created branch, instead of listing all branches. Now, instead of doing something you almost certainly didnt mean, git branch -l will list all of your repositorys branches, keeping in line with other commands that accept -l. [source] If youve ever been stuck or forgotten what a certain command or flag does, you might have run git --help (or git -h) to learn more. In Git 2.21, this invocation now follows aliases, and shows the aliased commands helptext. [source] In repositories with large on-disk checkouts, git status can take a long time to complete. In order to indicate that its making progress, the status command now displays a progress bar. [source] Many parts of Git have historically been implemented as shell scripts, calling into tools written in C to do the heavy lifting. While this allowed rapid prototyping, the resulting tools could often be slow due to the overhead of running many separate programs. There are continuing efforts to move these scripts into C, affecting git submodule, git bisect, and git rebase. You may notice rebase in particular being much faster, due to the hard work of the Summer of Code students, Pratik Karki and Alban Gruin. The -G option tells git log to only show commits whose diffs match a particular pattern. But until Git 2.21, it was searching binary files as if they were text, which made things slower and often produced confusing results. [source] Thats all for now We went through a few of the changes that have happened over the last couple of versions, but theres a lot more to discover. Read the release notes for 2.21, or review the release notes for previous versions in the Git repository. ",
        "Because git != GitHub, the actual change log can be found here: <a href=\"https://public-inbox.org/git/xmqqtvgtkq46.fsf@gitster-ct.c.googlers.com/\" rel=\"nofollow\">https://public-inbox.org/git/xmqqtvgtkq46.fsf@gitster-ct.c.g...</a>",
        "Detecting files that differ only in case being cloned onto a case-insensitive file system is a great feature. We recently ran into an issue when using the Nix build tool, which caches inputs based on a SHA hash, where it generated different hashes between Linux (w/ a case sensitive file system) and Mac (with a case insensitive one) machines.<p>Tracking that one down was pretty tricky. I didn't even consider that something at the Git level could be done to improve the situation!"
      ],
      "relevant": "true"
    },
    {
      "id": 20499070,
      "title": "GitHub is down",
      "search": [
        "GitHub is down",
        "Normal",
        "https://www.githubstatus.com/?",
        "All Systems Operational Git Operations ? Operational API Requests ? Operational Visit www.githubstatus.com for more information Operational Pull Requests ? Operational GitHub Actions ? Operational GitHub Packages ? Operational GitHub Pages ? Operational Operational Degraded Performance Partial Outage Major Outage Maintenance Past Incidents Nov 6, 2021 No incidents reported today. Nov 5, 2021 No incidents reported. Nov 4, 2021 Resolved - This incident has been resolved. Nov 4, 18:54 UTC Investigating - We are investigating reports of degraded performance for GitHub Actions. Nov 4, 18:13 UTC Nov 3, 2021 No incidents reported. Nov 2, 2021 No incidents reported. Nov 1, 2021 No incidents reported. Oct 31, 2021 No incidents reported. Oct 30, 2021 No incidents reported. Oct 29, 2021 No incidents reported. Oct 28, 2021 No incidents reported. Oct 27, 2021 No incidents reported. Oct 26, 2021 No incidents reported. Oct 25, 2021 No incidents reported. Oct 24, 2021 No incidents reported. Oct 23, 2021 No incidents reported. ",
        "Although it's nice that Git is Git and we can all mostly still work, it still seems foolish to rely on a single point of failure like Github. I've been toying around with the idea of creating a tool that would map the Git api to work with two+ hosting services at the same time. The effect would be something like, run \"$git push\" and it pushes to Github, Bitbucket, and Gitlab. I can't imagine something like this would be too difficult and would eliminate having to twiddle your thumbs while you wait for things to come back up.",
        "I sometimes look forward to outages like this just so I can read the post-downtime-resolution blog post that almost always follow. I find reading about how companies deal with issues when shit hits the fan to be really interesting."
      ],
      "relevant": "true"
    },
    {
      "id": 19750271,
      "title": "Gitlab 11.10 Released",
      "search": [
        "Gitlab 11.10 Released",
        "Normal",
        "https://about.gitlab.com/2019/04/22/gitlab-11-10-released/",
        "Easily see pipeline health across projects GitLab continues to add features to provide visibility into the DevOps lifecycle. This release enhances the Operations Dashboard with a powerful feature that provides an overview of pipeline status. This is handy even when looking at a single project's pipeline, but is especially valuable when using multi-project pipelines - common when you have a microservices architecture and you need to run a pipeline to test and deploy code housed in multiple different project repositories. Now you can get instant visibility at a glance into the health of all of your pipelines on the Operations Dashboard, no matter where they run. Run pipelines against merged results Over time its possible for your source and target branches to diverge, which can result in the scenario where both source and target pipelines pass, but the combined output fails. Now, you can run pipelines against the merged result prior to merging. This allows you to quickly catch errors that would only surface if you had rebased often, allowing for much quicker resolution of pipeline failures and more efficient usage of GitLab Runners. Further streamline collaboration With GitLab 11.10, we provide even more features to simplify collaboration and developer workflows. In a previous release, we introduced merge request suggestions, allowing a reviewer to suggest a one-line change in a merge request comment that can be readily committed from within the comment thread interface. Our users loved it and wanted more. Now, you can suggest a multi-line change, specifying which existing lines to remove, and introducing multiple lines of additions. Thank you for contributing improvement suggestions! And so much more So many great features are available in this release, like Scoped Labels, a more thorough Container Registry cleanup, Composable Auto DevOps, and the ability to purchase additional CI Runner minutes. Read on to learn about them all! Join us for an upcoming event This month's Most Valuable Person (MVP) is Takuya Noguchi This months MVP goes to Takuya Noguchi. Takuya made many contributions to GitLab, including fixing bugs, cleaning up both backend and frontend technical debt, as well as making UI improvements. Thank you! Key improvements released in GitLab 11.10 The Operations Dashboard in GitLab is a powerful feature allowing users to have an overview of project information throughout the entire GitLab instance. You add individual projects, one by one, so its flexible to whichever specific projects are of interest. With this release, we added pipeline status information to the Operations Dashboard. This helps teams view the pipeline health of all the projects that they care about, together in a single interface. Pipelines for Merged Results When working in a feature (source) branch, its normal to have it diverge over time from the target branch if you arent rebasing frequently. This can result in a situation where both the source and target branchs pipelines are green and there are no merge conflicts, but the combined output will result in a failed pipeline due to an incompatibility between the changes. By having your merge request pipeline automatically create a new ref that contains the combined merge result of the source and target branch, then running the pipeline against that ref, we can better ensure that the combined result will be valid. Please note that if you are using merge request pipelines (in any capacity) and you use private GitLab runners that are version 11.8 or older, you will need to upgrade them to avoid running into the issue described in gitlab-ee#11122. Users of GitLabs shared Runner fleet are not impacted. Suggest changes to multiple lines Collaborating on merge requests often involves spotting problems and suggesting a solution. In GitLab 11.6, we introduced support for suggesting a change to a single line. With 11.10, changes can now be suggested to multiple lines when leaving a comment on a merge request diff, and accepted with a single click, by any user with write permissions to the source branch. This new feature avoids the copy/paste workflow of old. Scoped Labels Scoped Labels enable teams to apply mutually exclusive labels (that share the same scope) on an issue, merge request, or epic, solving the use cases of custom fields and custom workflow states. They are configured simply using a special double colon syntax in the label title. Suppose you wanted a custom field in issues to track the platform operating system that your features target. And each issue should only target one platform. You would create labels platform::iOS, platform::Android, platform::Linux, and others, as necessary. Applying any one of these labels on a given issue would automatically remove any other existing label that starts with platform::, as desired. Suppose you have the labels workflow::development, workflow::review, and workflow::deployed, representing workflow states of your particular team. If an issue already has the label workflow::development applied, and a developer wanted to advance the issue to workflow::review, they would simply apply that label, and the workflow::development label would automatically be removed, as desired. This behavior already exists when you move issues across label lists in an issue board representing your teams workflow. But now team members who may not be working in an issue board directly, would still nonetheless be able to advance workflow states consistently in issues themselves. More thorough Container Registry cleanup In normal use of the Container Registry with CI pipelines, typically you will end up pushing many iterative revisions to the same tag. Due to the way Docker Distribution is implemented, the default behavior is to preserve all revisions in the system this ends up consuming a lot of space under this usage pattern. By using the -m parameter with registry-garbage-collect, administrators now have an easy way to wipe out these historical revisions and free up valuable storage space. Purchase add-on CI Runner minutes Users on GitLab.coms paid plans (Gold, Silver, Bronze) can now purchase additional CI Runner minutes. Previously, users were limited by the minutes quota included in their plan. This improvement enables users to proactively purchase minutes in addition to their free minutes, which reduces the potential for any interruptions in service due to stopped pipelines. The current price is $8 for 1,000 minutes and there is no cap to how many add-on minutes you can buy. Your add-on minutes will only begin to be used once your monthly quota has been used and whatever add-on minutes are left at the end of the month will roll over. In a future release, we aim to extend this to Free plans as well. Composable Auto DevOps Auto DevOps enables teams to adopt modern DevOps practices with little to no effort. Starting in GitLab 11.10 each job of Auto DevOps is being made available as an independent template. Using the includes feature of GitLab CI, users can include only certain stages of Auto DevOps while continuing to use their own custom gitlab-ci.yml. This will enable teams to include just the desired jobs while taking advantage of any updates made upstream. Until now, managing group membership on GitLab.com was a manual effort. Youre now able to use SAML SSO and manage group membership with SCIM, allowing your organization to create, remove, and update users on GitLab.com. This is especially useful for enterprises who typically manage large numbers of users with centralized identity providers. Now, youre able to use a provider like Azure Active Directory as the single source of truth and feel confident that your users will be provisioned and de-provisioned automatically based on your identity provider, not by hand. Previously, SAML-based SSO for groups required that a user sign in with both their GitLab user credentials and their identity provider. Now, a user will be able to use SSO to immediately sign in with a GitLab user linked to the configured group. This removes the need to sign in twice, making SAML SSO more convenient and useful for enterprises using it on GitLab.com. Other improvements in GitLab 11.10 Child Epics roadmap In a previous release, we added Child Epics the ability to have epics of epics to help teams manage work breakdown structures. Child epics are shown in the epic page of the parent epic. With this release, you can now see a roadmap view of the child epics in the parent epic page itself. This helps teams see the timeline view of those child epics, allowing you to manage time dependencies. Filter merge requests by target branch Git workflows for releasing or deploying software often involve multiple long-running branches, either for backporting fixes to older versions (e.g. stable-11-9) or moving through a QA process to product (e.g. integration), but finding the merge requests that target these branches can be difficult among many open merge requests. The merge request list for projects and groups can now be filtered by the target branch of the merge request, making it simpler to find the merge request you are looking for. Thank you, Hiroyuki Sato, for the contribution! Sort Wiki pages by created date A projects Wiki allows teams to share documentation and other important information conveniently, side by side with source code and issues. In this release, the list of pages in a Wiki can be sorted by created date and title, allowing users to locate recently created content quickly. See Load Balancer metrics in your Grafana dashboard Ensuring your GitLab instance stays healthy is critical. Weve previously given you default dashboards to review in our bundled-in Grafana instance. Starting with this release, we now include additional dashboards to monitor your NGINX load balancers. Multiple queries per chart GitLab allows you to create charts to visualize the metrics you are collecting. Often, such as when you want to see the maximum and average value of a metric, its crucial to be able to visualize multiple values on the same chart. Starting with this release, you can now do so. Enrich Container Scanning report with more metadata This release enriches the Container Scanning report with more metadata, adding impacted component (a Clair feature) to the existing metadata: priority, identifier (with a link on mitre.org), and affected layer (ex: debian:8). Multi-module Maven projects support for Dependency Scanning This release enables multi-module Maven projects for GitLab Dependency Scanning. Previously, if a sub-module had a dependency with another sub-module sibling, it could not resolve the download from the Maven Central repository. Now a multi-module Maven project is created with two modules and a dependency between the two modules. The sibling dependency is now available in the local Maven repo, permitting the build to continue. Allow users to change the path for cloning in CI By default, the GitLab Runner clones the project to a unique subpath of the $CI_BUILDS_DIR. However, for some projects, such as Golang projects, there may be a requirement to have the code cloned to a specific directory to be built. In GitLab 11.10, weve introduced a variable called GIT_CLONE_PATH that allows users to specify the specific path that the GitLab Runner will clone to before starting the job. Enable/disable Auto DevOps at the Group level Enabling Auto DevOps for your GitLab.com project provides an easy way to get started with modern DevOps workflows, from build all the way to deploy. Starting with GitLab 11.10 weve added the ability to enable/disable Auto DevOps for all the projects that are part of any given group. Update Kubernetes deployments label selector Deploy boards provide an easy way to gain insight into your Kubernetes deployments. As part of this release, were updating the way labels are matched to deployments; deploy boards will now match by app.example.com/app and app.example.com/env or app. This will allow us to prevent conflicts when doing filtering and risk incorrect deploys associated to the project. Additionally, starting in GitLab 12.0 we will remove app label matching from Kubernetes deployment selector and will instead match only on app.example.com/app and app.example.com/env. Group Runners for group-level clusters Group-level clusters now support the installation of GitLab Runner. Group-level Kubernetes runners will appear for child projects as group runners tagged with the labels cluster and kubernetes. Add control for git clean flags for GitLab CI/CD jobs By default, GitLab Runner runs a git clean as part of the process of checking out your code while running a job in GitLab CI/CD. In GitLab 11.10, were adding the ability for users to control the flags passed to the git clean command. This will help teams who have dedicated runners or are building projects from large mono repositories to manage the checkout process prior to executing their scripts. The new variable GIT_CLEAN_FLAGS defaults to -ffdx and accepts all the possible options of the git clean command. Secure environments may require checking with an additional external authorization resource to permit project access. We added support for this additional layer of access control in 10.6, and weve heard requests from the community to move this functionality to Core. Were happy to do this for External Authorization and bring this additional level of security to Core instances, since its a feature cared about by individual contributors. Merge request popovers In this release, we introduce enriched popovers when hovering over a merge request link. While we previously only displayed the title of the merge request, you can now view the merge request status, CI pipeline status, title, and short URL. In future releases, we plan to add additional important information like assignees and milestones and bring popovers to issues too. Push and merge when pipeline succeeds Trunk-based development claims that long-running branches should be avoided in favor of small, short-lived, single-owner branches. For the smallest changes it is not uncommon to push directly to the target branch, but this runs the risk of breaking the build. In this release, GitLab supports new Git push options to open a merge request automatically, set the target branch, and enable merge when the pipeline succeeds via the command line, at the moment that you push to your branch. Improved integration with external monitoring dashboards GitLab can access multiple Prometheus servers (at the environment, project and soon group levels) but the complexity of multiple endpoints can be difficult or unsupported by common dashboarding tools. In this release teams can now interact with a single Prometheus API interface, making integration with services like Grafana much simpler. Monitor resources requested by your cluster GitLab can assist you by monitoring the Kubernetes cluster you use for your staging and production applications. Starting in this release, you can monitor the requested CPU and Memory resources by your cluster helping you spot potential application impacts before they happen. SAST for Elixir We are continuing to add support for more languages and depth in our security scans. With this release, we enable security scanning for projects created using Elixir, now broadened to projects created using the Phoenix framework. Show DAST results in the Group Security Dashboard We have added Dynamic Application Security Testing (DAST) results in the Group Security Dashboard to accompany results already present for SAST, Container Scanning, and Dependency Scanning. Add metrics report type to merge requests GitLab already provides several report types to be included directly into the merge request from Code Quality and Unit Test reports from the Verify stage to SAST and DAST from the Secure stage. While those specific report types are very valuable, there is also value in providing a primitive that can be used across many different types of use cases. In GitLab 11.10 we are shipping metrics reporting directly in the merge request that expects a simple key/value pair of metrics. This will allow users to track any changes, including custom metrics, over time and how they change with a given merge request. Use cases such as memory usage, specialized load testing, and other code health statuses can be converted to simple metrics that will then be exposed directly in the MR alongside the other built-in reports. Simple masking of protected variables in logs GitLab provides several ways to protect and limit the scope of variables in GitLab CI/CD. However, there are still ways that variables can leak into build logs, either intentionally or unintentionally. GitLab takes risk management and audit seriously and continues to add features to help with compliance efforts. In GitLab 11.10, weve added the ability to mask certain types of variables if they are found in the job trace logs, adding a level of protection against accidentally leaking the content of those variables into the logs. Also, GitLab will now automatically mask many of the built-in token variables. Simplified and improved license page To improve the user experience and make handling license keys easier, weve redesigned the license page in the admin panel and emphasized the most important elements of the page. Just-in-time Kubernetes resource creation GitLabs Kubernetes integration takes advantage of RBAC security by creating a service account and a dedicated namespace for each GitLab project. Starting with this release, to maximize the efficiency with which these resources are created, they will be created only when they are needed for deployment. When a Kubernetes deployment takes place, GitLab CI will create the resources prior to deployment. Show function invocation count for Knative functions Functions deployed with GitLab Serverless will now include the number of invocations received for the particular function. Showing the number of invocations requires Prometheus to be installed on the cluster where Knative is installed. Allow Developers to create projects in groups in Core We added a configurable option to allow the Developer role to create projects in groups back in 10.5, and were adding this option to Core. Creating projects is a key capability for productivity in GitLab, and moving this option to Core helps reduce barriers when members of an instance want to work on something new. Fix returned project_id in blob search API with Elasticsearch We fixed a bug in the blob search API with Elasticsearch that was incorrectly returning 0 for project_id. You will need to reindex Elasticsearch to get the correct project_id values after installing this version of GitLab. Omnibus improvements The following improvements have been made to Omnibus in GitLab 11.10: GitLab 11.10 includes Mattermost 5.9.0, an open source Slack-alternative whose newest release includes a new Integrations Directory, a simple way to migrate data from Hipchat, and much more. This version also includes security updates and upgrading is recommended. GitLab dashboards are now pre-loaded in the bundled Grafana, making it even easier to begin monitoring your instance of GitLab. We have added support to clean up old container images from the Docker registry. We have updated ca-certs to 2019-01-23. GitLab chart improvements The following improvement has been made to GitLab charts: Support for Elasticsearch has been added. Deprecations GitLab Geo will enforce Hashed Storage in GitLab 12.0 GitLab Geo requires Hashed Storage to mitigate race conditions on secondary nodes. This was noted in gitlab-ce#40970. In GitLab 11.5, we added this requirement to the Geo documentation in gitlab-ee#8053. With GitLab 11.6, sudo gitlab-rake gitlab:geo:check checks that Hashed Storage is enabled, and all projects are migrated. See gitlab-ee#8289. If you are using Geo, please run this check and migrate as soon as possible. In GitLab 11.8, a permanently dismissable warning is displayed on the Admin Area Geo Nodes page if the above checks are not resolved: gitlab-ee!8433. In GitLab 12.0, Geo will enforce the Hashed Storage requirement. See gitlab-ee#8690. Planned removal date: Jun. 22, 2019 Ubuntu 14.04 support GitLab 11.10 will be the last release with support for Ubuntu 14.04. Canonical has announced that standard support for Ubuntu 14.04 will end on April 2019. We recommend that users upgrade to one of the currently supported LTS versions Ubuntu 16.04 or Ubuntu 18.04. Planned removal date: May 22, 2019 Limit maximum number of pipelines created by a single push Previously, GitLab would create pipelines for the HEAD of every branch included in a push. That makes sense for developers that may be pushing more than one change at a time (say to a feature branch, and the develop branch). However, when pushing a large repository with many active branches perhaps to move, mirror, or fork it from another location - it does not make sense to create a pipeline for every branch. Starting in GitLab 11.10, we will create a maximum of 4 pipelines during a push operation. Planned removal date: May 22, 2019 Deprecate legacy code paths GitLab Runner Since GitLab 11.9, GitLab Runner has been using a new method for cloning/fetching the repository. Currently, GitLab Runner will use the old method if the new one is not supported. Please see this issue for additional details. In GitLab 11.0 we changed how the metrics server is configured for GitLab Runner. metrics_server will be removed in favor of listen_address in GitLab 12.0. Please see this issue for additional details. In 11.3, GitLab Runner started supporting multiple cache providers; this resulted in new settings for S3 specific configuration. In the documentation, there is a table of what changed, and how to migrate to the new configuration. Please see this issue for additional details. These paths will no longer be available in GitLab 12.0. As a user, you dont have to change anything apart from making sure the GitLab instance is running 11.9+ when upgrading to GitLab Runner 12.0. Planned removal date: Jun. 22, 2019 Deprecate entrypoint feature flag for GitLab Runner In 11.4 GitLab Runner introduced a feature flag FF_K8S_USE_ENTRYPOINT_OVER_COMMAND in order to fix issues like #2338 & #3536. In GitLab 12.0, we will switch to the correct behavior as if the feature flag was turned off. Please see this issue for additional details. Planned removal date: Jun. 22, 2019 Deprecate support of Linux distribution that reached EOL for GitLab Runner Some Linux distributions in which you could install GitLab Runner have reached End of Life support. In GitLab 12.0, GitLab Runner will no longer distribute packages to those Linux distributions. A full list of distributions which are no longer supported can be found in our documentation. Thanks, Javier Jardn for your contribution! Planned removal date: Jun. 22, 2019 Remove legacy GitLab Runner Helper commands As part of our effort to support a Windows Docker executor, we had to deprecate some old commands that are used for the helper image. In GitLab 12.0, GitLab Runner will start using the new commands. This only affects users who are overriding the helper image. Please see this issue for additional details. Planned removal date: Jun. 22, 2019 Remove legacy git clean mechanism from GitLab Runner With GitLab Runner 11.10 were introducing a way to configure how git clean command is being executed by Runner. Additionally, the new cleanup strategy removes the usage of git reset and moves the git clean command after the checkout step. Since this is a behavior change that may affect some users, weve prepared a FF_USE_LEGACY_GIT_CLEAN_STRATEGY feature flag. When set to true it will restore the legacy cleanup strategy. More about how to use feature flags in GitLab Runner can be found in the documentation In GitLab Runner 12.0, GitLab Runner will drop support for the legacy cleanup strategy and remove the ability to restore it with a feature flag. Please see this issue for additional details. Planned removal date: Jun. 22, 2019 System Info section in the admin panel GitLab presents information about your GitLab instance at admin/system_info, but this information can be inaccurate. Were removing this section of the admin panel in GitLab 12.0 and recommend using other monitoring capabilities. Planned removal date: Jun. 22, 2019 Support for Prometheus 1.x in Omnibus GitLab With GitLab 11.4, the bundled Prometheus 1.0 version is deprecated in Omnibus GitLab. Prometheus 2.0 is now included. However, the metrics format is incompatible with 1.0. Existing installations can upgrade to 2.0 and optionally migrate their data using an included tool. With GitLab 12.0, any installation not yet running Prometheus 2.0 will be automatically upgraded. Metric data from Prometheus 1.0 will not be migrated and will be lost. Planned removal date: Jun. 22, 2019 GitLab Subscription Plans GitLab is available in self-managed and cloud SaaS options. Self-managed: Deploy on-premises or on your favorite cloud platform. Free: For small teams, personal projects, or GitLab trials with unlimited time. Premium: For distributed teams who need advanced features, high availability, and 24/7 support. Ultimate: For enterprises that want to align strategy and execution with enhanced security and compliance. Cloud SaaS - GitLab.com: hosted, managed, and administered by GitLab with free and paid subscriptions for individuals and teams. Free: Unlimited private repositories and unlimited collaborators on a project. Premium: For teams that need more robust DevOps capabilities, compliance and faster support. Ultimate: Great with many CI/CD jobs. Every public project gets the features of Ultimate for free irrespective of their plan. Cover image licensed under Unsplash ",
        "GitLab has really come a long way in the past few years. The days of being a github-alike are long gone. Very happy to see them continue to find success.",
        "Can't help but feel that their focus on moving all operation insights into gitlab itself will not be as successful as they want it to be (as far as I read, their goal was to replace their operations and monitoring tools with gitlab itself[1]). I've worked with the ultimate edition for a year and the kubernetes integration is nowhere close to the insight you would get from google, amazon or azure in terms of insight and integration with ops-land. I wish all these hours were spent on improving the developer lifecycle instead.<p>I can understand how their huge success of \"built-in CI\" quickly leads to \"built-in XYZ\", but competing with github that lets other companies solve developer/ci problems via marketplace (and now CI via their new terraform actions) may lead to loosing market-leader [my take on their product] position for a code/test/review/merge ecosystem.<p>[1]: <a href=\"https://about.gitlab.com/2018/10/01/gitlab-product-vision/\" rel=\"nofollow\">https://about.gitlab.com/2018/10/01/gitlab-product-vision/</a>"
      ],
      "relevant": "true"
    },
    {
      "id": 19805938,
      "title": "GitHub Learning Lab",
      "search": [
        "GitHub Learning Lab",
        "Normal",
        "https://lab.github.com/",
        "Our most popular courses Introduction to GitHub The GitHub Training Team If you are looking for a quick and fun introduction to GitHub, you've found it. This class will get you started using GitHub in less than an hour. Git GitHub Pages Branches Commits Pull Requests Learning should be fun There are no simulations or boring tutorials here, just hands-on lessons created with by the GitHub community and taught by the friendly Learning Lab bot. Real projects Learn new skills while working in your own copy of a real project. Helpful bot Our friendly bot provides instructions and feedback throughout your journey. Real workflow Everything happens in GitHub Issues and Pull Requests. Our Learning Paths First Day on GitHub The GitHub Training Team Welcome to GitHub! We're so glad you're here. We know it can look overwhelming at first, so we've put together a few of our favorite courses for people logging in for the first time What is GitHub? Introduction to GitHub Git Handbook First Week on GitHub The GitHub Training Team After you've mastered the basics, learn some of the fun things you can do on GitHub. From GitHub Pages to building projects with your friends, this path will give you plenty of new ideas. Discover GitHub Pages GitHub Pages Reviewing pull requests GitHub Actions: Hello World GitHub Actions: Continuous Integration GitHub Actions: Publish to GitHub Packages Learn GitHub with GitHub Uploading your project to GitHub The GitHub Training Team Youre an upload away from using a full suite of development tools and premier third-party apps on GitHub. This course helps you seamlessly upload your code to GitHub and introduces you to exciting next steps to elevate your project. Languages and Tools Introduction to HTML The GitHub Training Team If you are looking for a quick and fun introduction to the exciting world of programming, this course is for you. Learn fundamental HTML skills and build your first webpage in less than an hour. Introduction to Node with Express everydeveloper Node.js gives you the ability to run JavaScript files on the server-side. Express is a library for Node.js, that allows you to make requests to different \"endpoints\" and get a response back. Node Express JavaScript JSON API Intermediate NodeJS Course everydeveloper This tutorial expands on concepts in the intro to Node.js and Express.js course. You will learn how to use a database (MongoDB) to Create, Read, Update, and Delete data. node.js express.js mongoose.js JavaScript MongoDB Introduction to PHP everydeveloper PHP is a server-side programming language that can insert dynamic code into your HTML. PHP is used in popular content management systems, such as WordPress and Drupal. Notating with LilyPond gitmusical LilyPond is an open source technology for notating music in plain text files. In this course, we'll cover the fundamentals of music notation in LilyPond. GitHub Actions DevOps with GitHub CodeQL U-Boot Challenge (C/C++) The GitHub Training Team Learn to use CodeQL, a query language that helps find bugs in source code. Find 9 remote code execution vulnerabilities in the open-source project Das U-Boot, and join the growing community of security researchers using CodeQL. Enterprise on GitHub InnerSource fundamentals The GitHub Training Team Organizations of all sizes and in all industries are chatting about InnerSource concepts. This course walks you through some of the key concepts of InnerSource and helps you build up an internal toolkit for adopting InnerSource practices. Create an open source program The GitHub Training Team Learn how to work alongside the open source communities that build software you're already using, and put your business at the forefront of the world's most innovative and secure code. Open source Enterprise Licensing Templates Guidelines ",
        "Not trying to weaken the GitLab brand at all... /s",
        "A Very good SEO move, to stir some of the 'lab' traffic away from gitlab."
      ],
      "relevant": "true"
    },
    {
      "id": 21041673,
      "title": "Gitlab 12.3 Released",
      "search": [
        "Gitlab 12.3 Released",
        "Normal",
        "https://about.gitlab.com/2019/09/22/gitlab-12-3-released/",
        "This month's release of GitLab 12.3 is especially exciting following an eventful week in which we hosted our first GitLab Users Conference in Brooklyn New York and announced the completion of a $268 million Series E round of fundraising; which will enable us to invest in making all of our DevOps platform offerings, including monitoring, security, and planning, best in class. Modern web applications are exposed to new risk from many places, including potentially every client that connects and sends traffic. A Web Application Firewall (WAF) provides monitoring and rules to protect applications in production. In GitLab 12.3 we are shipping our first iteration of a Web Application Firewall built into the GitLab SDLC platform. Its focus is on monitoring and reporting of security concerns related to your Kubernetes clusters. Future releases will expand the WAF capabilities to block malicious traffic, create and manage firewall rules, and inform earlier stages of development to take action to further reduce risk. Software delivery teams everywhere need the right information and insight in order to improve their productivity and efficiency. Too often, invisible bottlenecks and roadblocks force teams to wait and waste time rather than delivering new features. Beginning with 12.3, were starting to release new analytics features to help teams and leaders better understand their overall productivity and effectiveness for both Groups and Projects. Productivity Analytics will help teams and their leaders discover best practices to improve productivity. Initially focusing on the time it takes to merge MRs, GitLab will make it possible to drill into the data and learn insight that can guide future improvements. In many organizations, leaders are responsible for multiple projects and Group level analytics workspace is intended to provide productivity and performance insight and visibility across multiple projects. These two features are only the first in a series of updates that will specifically improve visibility and insight so that teams can become more efficient. Compliance with policies and procedures is a common challenge that software teams face. For many GitLab users, having development teams collaborate in a single application makes compliance easier. In this 12.3 release of GitLab, we're including several features that will continue to streamline efforts to reduce compliance risks. MR approval rules provides a way to prevent teams from merging in code that introduces unsupported licenses. Require code owner approval per branch makes it possible to protect branches and require code owner approval of changes. And much more! There are so many great features within GitLab 12.3 that we couldnt possibly highlight them all (even though we really want to). Better resource visibility with Global view for group-level cluster deployments/environments, more efficient Git fetches with Compress Git ref advertisements over HTTP, and more efficient reviews with Keyboard Shortcut for Next and Previous Unresolved Discussion Register now to join us at our first European user conference in London on Oct 9! Join us for an upcoming event This month's Most Valuable Person (MVP) is Cdric Tabin Cdrics contribution to GitLab 12.3 adds a new CI job keyword allowing interruptible builds. They worked for more than 9 months contributing this feature and working with our review teams to get it across the line. Thanks so much to Cdric for their tireless effort on this contribution! Key improvements released in GitLab 12.3 Web Application Firewall for Kubernetes Ingress GitLab now adds the modsecurity Web Application Firewall (WAF) plug-in to your cluster when you install the Ingress app in your Kubernetes cluster. The WAF is able to determine whether or not HTTP or HTTPS traffic to your app contains malicious code, such as SQL injection, cross-site scripting, or trojans. The WAF is pre-configured with a powerful set of rules, the OWASP ModSecurity Core Rules (CRS), to detect many different types of attacks out-of-the-box. The documentation describes how to view the WAF logs so you can see what type of malicious traffic your app is subjected to when it is running in production. Productivity Analytics Currently there are relatively few sources of data and analytics, which can help engineering leaders understand their team, project, and group productivity. As Peter Drucker has once said, Whats measured improves. Subscribing to this view, we are releasing our first iteration of Productivity Analytics in order to help engineering leaders uncover patterns and best practices to improve overall productivity. The focus of this release is on the time it takes to merge MRs depending on their size. Users can make use of our existing filters and drill down to a specific author or label in a group for a specific date range. As we go forward and iterate on productivity analytics, we will add additional data points in order to help identify dependencies which may be contributing to increased active development and/or wait times. Note that in this initial release of Productivity Analytics, we have not backfilled the historical data for the newly derived metrics to ensure that this background process does not adversely impact the upgrade from 12.2 to 12.3. Youre welcome to follow the issue, where we are working on that here. Global view for group-level cluster deployments/environments Provisioning a group-level cluster is a great way for operators to provide an application development platform for developers. Scaling cluster resources can be challenging and requires a global view of resource usage. The new Environments section of the cluster page provides an overview of all the projects that are making use of the Kubernetes cluster, including the deployments/environments that have been provisioned and the numbers of pods used by each environment. Leverage merge request approvals to prevent merging prohibited licenses MVC If you have strict License Compliance restrictions, you may set the License Compliance feature to disallow a merge when a blacklisted license is found in a merge request. This prevents the new introduction of licenses which you have expressly prohibited. Currently you can set the approvers for the License-Check group in project settings then require the check by following the directions outlined in the documentation. Other improvements in GitLab 12.3 Analytics Workspace Engineering and product teams can span multiple GitLab groups and projects, yet most of our analytics have traditionally been developed at the project level. This is why we created a workspace where users can aggregate insights across groups, subgroups, and projects. The Analytics workspace will make it easier for teams and leaders to analyze and manage team metrics. The workspace will be available in Core. However, in some cases, specific features will be available to Enterprise Edition customers. As we move to the Analysis workspace, we will ensure that existing project-level analytics functionality is available to Community Edition users when moved to the new workspace. In GitLab 12.3, we are releasing the first iteration of group and project level Productivity Analytics and group-level Cycle Analytics. In subsequent releases, we will enable the selection of multiple groups and subgroups; porting all analytics features for an instance. We would love your feedback and input on the strategy for Analytics/Value Stream Management Design Management notifications In GitLab 12.2 we released our initial iteration of Design Management. An important part of continuing to evolve is to ensure users are properly notified about these activities. Conversations in designs will now create To-Dos for mentioned users and send notifications based on their preferences. This helps to ensure that important feedback isnt missed and can be actioned. In a future release, well add those conversations to the main discussion tab for an easier conversation flow. API for Merge Request Approval Rules Approval Rules for Merge Requests allow you to communicate who should participate in code reviews by specifying the eligible approvers and the minimum number of approvals for each. Approval rules are shown in the merge request widget so the next reviewer can easily be spotted. In GitLab 12.3, support for Approval Rules has been added to the API for Projects and Merge Requests. Keyboard shortcut for next and previous unresolved discussion Reviewing, discussing and resolving feedback is the basis of code review in GitLab. The Jump to next unresolved discussion button makes it easy to quickly jump from discussion to discussion. In GitLab 12.3, the new n and p keyboard shortcuts to move to the next and previous unresolved discussions in Merge Requests make it even more convenient to review changes. API to require merge request approval by code owners per branch Using merge request approvals to restrict how code is pushed to protected branches is helpful for promoting code quality and implementing compliance controls. But not all merge requests target stable branches, and not all stable branches need the same controls. In GitLab 12.3, it is possible to require code owners approval for specific branches (through the API) to prevent directly pushing changes to files with code owners, or merging changes without the code owners approval. Note: This feature is only available via the API in GitLab 12.3. In GitLab 12.4 it will be available through the Protected Branch settings. Follow issue #13251 for updates. Flexible rules keyword for controlling pipeline behaviors Only/except rules in pipelines can have a lot of implicit behaviors, and as more and more are added to your pipelines, it can become very difficult to understand if a given job is going to run or not in different situations. We are introducing a new rules: syntax that will make it much easier to implement and understand complex rules. This syntax is optional and can exist in the same pipeline, but not the same jobs, as the current only/except approach. only/except: external_pull_requests for external repositories GitLab CI has an external repos capability intended to allow customers to use external repos for source control and GitLab for CI/CD. Until now, however, the CI_PIPELINE_SOURCE always showed push because it was based on the pull mirror rather than the source external repo or webhook. This prevented GitLab us from correctly supporting only/except: merge_requests-style options. In the 12.3 release weve resolved this limitation. Remove container images from CI/CD The GitLab Container Registry allows users to leverage GitLab CI/CD to build and push images/tags to their project. Changes to the Container Registry are made by a service account called CI Registry User that is invoked from .gitlab-ci.yml with the predefined environment variable CI_REGISTRY_USER. Previously, this service account could push new tags to the registry, but it lacked permissions to untag images. This prevented branch-specific images from being removed, resulting in additional storage costs and creating difficulty when navigating the registry user interface due to the large number of additional, unneeded tags. In 12.3 we have expanded the permissions of CI_REGISTRY_USER to allow for untagging of images so you can clean up branch-specific tags as part of your regular CI/CD workflow and use GitLab CI/CD to automate your cleanup scripts. This issue is part of a larger epic to lower the cost of the Container Registry by improving storage management. Validate domains when performing full DAST active scans You can now ensure DAST only performs active scans against domains which are intentionally configured for DAST scanning. This helps to ensure that DAST active scans are not unintentionally run against domains which could be serving content or being used in a production capacity. There is no change to passive DAST scans, since passive scanning does not potentially negatively impact scanned sites. SAST Spotbugs analyzer updated for Java 11 The SAST SpotBugs analyzer has been updated to allow scanning of code written with Java 11. You can enable this by setting the SAST_JAVA_VERSION environment variable in your project. Run Pipeline button for Merge Request Pipelines Pipelines for merge requests recently introduced a new way to run a pipeline in the context of a merge request, but the only way to trigger a new run of one of these pipelines was through a push. In this release weve added a button to start a new pipeline, making it much easier to retry a failed pipeline. User-defined CI variables available to docker build with Auto DevOps CI variables allow you to tailor how processes are run to build your application as part of your CI pipeline. Starting in GitLab 12.3, you can extend the availability of user-defined CI variables to the docker build step in Auto DevOps. The data is made available as a new build secret value. List one or more variables using the AUTO_DEVOPS_BUILD_IMAGE_FORWARDED_CI_VARIABLES variable and it will be made available to use in docker build. Knative for group and instance-level clusters Group and instance-level clusters now support the installation of Knative, the Kubernetes-based platform to deploy and manage serverless workloads. This will allow multiple projects to make use of GitLab Serverless features leveraging a single cluster. Line charts for metrics dashboard When it comes to visualizing metrics, oftentimes users would like to choose different types of visualization for specific metrics (e.g., line chart for CPU, area chart for disk space). To help achieve this, we added line charts as a part of our effort to enhance our dashboard offering around monitoring. Quick actions to add/remove Zoom meetings on issues Synchronous collaboration is a critical part of any fire-fight. We are streamlining the number of steps it takes to spin up a conference bridge and engage all required parties by embedding this functionality, using Zoom, directly in an issue. Once a user has started a Zoom meeting, they can attach it to an issue using a quick action and inputting the Zoom meeting URL (e.g. /zoom https://gitlab.zoom.us/s/123456). A button will appear at the top of the issue giving users direct access to the conference bridge. When the incident has resolved, the Zoom meeting can be removed using /remove_zoom. This feature is generally available on GitLab.com and feature flagged for use on self-managed instances. If you are interested in taking advantage of this feature for your self-managed instance of GitLab, operators can enable the issue_zoom_integration feature flag. In next months release of GitLab 12.4 we plan to remove the feature flag and make the Zoom Issue integration generally available for all self-managed users. Geo displays secondary lag when pushing via Git HTTP Fetching large amounts of data can take a long time for users in remote locations. Replicating repositories with Geo reduces the time it takes to clone and fetch large repositories by creating read-only secondary nodes near remote user. Because secondary nodes lag behind the primary node, GitLab now provides an estimate of replication lag whenever git push is used over HTTP. This raises the visibility of using a Geo node and allows users to detect increases in replication lag and report them to systems administrators. Because of protocol limitations, this message is not available when using git pull. Disable 2FA for selected OAuth providers Organizations using enforced two-factor authentication and an identity provider also using 2FA may find the requirement to authenticate twice frustrating. Thanks to a community contribution, youre now able to bypass 2FA for selected OAuth identity providers in GitLab. For those using providers that handle 2FA, this makes logging into GitLab a friendlier and easier experience. Thanks to dodocat for the contribution! IP address restriction supports multiple subnets Iterating on restricting group activity by IP address, GitLab 12.3 introduces the ability to specify multiple IP subnets. For geographically distributed organizations, this helps this feature shine; instead of specifying a single (and overly permissive) range, large organizations can now restrict incoming traffic to their specific needs. Design Management status and discussion counts In GitLab 12.2 we released the first iteration of Design Management, which allowed uploading designs directly to issues. They were uploaded in a separate tab within issues and the activity in each version of Designs wasnt clear to the user. Now, when designs are uploaded, status icons are added in each version to let you know if its a new design or a change to an existing design. We also added discussion counts on designs to better inform users of conversations happening. Were excited about these additions to Design Management to help improve the collaboration and conversation inside of GitLab for design and engineering teams. Compress Git ref advertisements over HTTP When fetching changes to a Git repository, the Git server advertises a list of all the branches and tags in the repository. This is called ref advertisement and can be many megabytes for large projects. In GitLab 12.3, when fetching over HTTP, the ref advertisement will be compressed for supported clients reducing the amount of data being transferred and making fetch operations faster. On an average weekday, GitLab.com serves about 850GB of ref advertisements over HTTP. After enabling ref compression, bytes transferred has decreased by approximately 70 percent. Audit logs for Git Push events (Beta) Git history can be rewritten to change commits, authors and timestamps, which makes it possible to craft clear and useful history for future developers. For audit, this is a problem. In GitLab 12.3, Git push events that add commits, rewrite history or otherwise modify the repository can be added to the audit log. Audit logs for push events are disabled by default to prevent performance degradation on GitLab instances with very high Git write traffic. In an upcoming release, Audit Logs for Git push events will be enabled by default. Follow #7865 for updates. Smarter Web IDE default commit options Previously the Web IDE defaulted to Commit to current branch when making a commit. This made it easy for those with permissions to accidentally push changes to master or other protected branches. Now when making changes in the Web IDE, the default commit options are smarter to prevent making changes to the wrong branch. Smarter commit options prevent accidental pushes to master and protected branches for users with write access. When the user has no write access, additional details are provided as to why options are unavailable. Additionally, the new commit options also support commits to a non-default branch with or without an existing Merge Request. Per-job timeouts for CI/CD pipelines Different jobs have different execution characteristics and may need different timeouts to be set on a per-job basis. Timeouts can be configured by adding the timeout: keyword to your job in .gitlab-ci.yml, along with a number to indicate the number of minutes to wait before the job fails. Thanks to Michal Siwek for the contribution. interruptible keyword to indicate if a job can be safely canceled The new interruptible keyword can be used to indicate whether or not a job should be canceled if made redundant by a newer run of the same job. The keyword defaults to false, so it should be used to specify jobs that are safe to stop. This value will only be used if the automatic cancellation of redundant pipelines feature is enabled. This helps avoid duplication of unnecessary jobs across your pipelines, reducing costs and making your pipelines more efficient. Due to a bug in the Runner, some executors do not stop in-progress jobs when cancelled. This is planned to be fixed in 12.4. Status checking for pipeline triggers Weve recently improved the way cross-project pipelines can trigger each other, but one thing still missing was having the triggering pipeline wait or confirm success of the triggered pipeline. It was possible using API polling, but in this release weve introduced the depends and wait strategies where this can be handled automatically for you. If you are triggering a pipeline you want to depend on, it will wait for the pipeline to complete and will verify it succeeds before finishing the triggering job. If you choose wait, it will wait for it to finish but proceed regardless of pass/fail status. API endpoint to list the Docker images/tags of a group The GitLab Container Registry allows users to build and push Docker images/tags to their project from the command line, CI/CD, or from an API. However, until GitLab 12.3 we did not offer any visibility into images/tags at the group level, a popular request from users. We have added two API endpoints that will give visibility into which images and tags exist at the group level. This is the first step in helping improve visibility and discoverability for the Container Registry. Next, well leverage the API to create a group-level browser as part of the Container Registry user interface. SAST scanning without Docker-in-Docker SAST scans can now optionally be done without using Docker-in-Docker. This means SAST scanning can be configured to not need elevated privileges. Edit vulnerability dismissal reasons Vulnerability dismissal reasons can now be edited and deleted. This allows you to add and update context for a vulnerability as you learn more over time. Improve Pages initial setup experience To improve the Pages user experience, we added a banner that notifies users of the possible initial setup time. We understand it can be frustrating to see the Congratulations message without the page being available. The banner helps make it more clear what to expect. Show Kubernetes cluster used for deployment The jobs detail page now displays the name of the Kubernetes cluster that was used for the given deployment. Project owners and maintainers are presented with a link on the cluster name which will link directly to the cluster details page. JupyterHub for group-level Kubernetes clusters Group-level clusters now support the installation of JupyterHub, a multi-user service for easily launching notebooks as well as creating runbooks for operators. This extends the availability of JupyterHub to both project-level and group-level clusters. Close issue via slash command in Slack Chat tools are required during fire-fights to resolve modern IT incidents. This tool needs to be closely integrated with the systems you are managing and the tools where you will actually perform remediation. As much as possible, you want to minimize context and tool switching while youre working to restore services and update your external stakeholders. In 12.3, we have added an additional slash command to the suite of commands we offer with our ChatOps product based on Slack. Issues can now be closed from Slack without needing to switch tools, just locate the issue in question, and manually close it. You can close it from where you are working. Geo natively supports Docker Registry replication Geo natively supports replicating a Docker Registry between primary and secondary Geo nodes. This allows Geo users to use a Docker Registry on a close-by secondary node. This approach is storage-agnostic and can be used for object storage, such as S3, or local storage. When using distributed object storage (e.g. S3) for a Docker Registry, the primary and secondary Geo nodes can use the same storage type. This approach does not rely on Geos native replication ability. API activity included in IP address group restriction GitLab 12.0 saw the introduction of restricting a groups activity by IP address. Weve iterated on this feature to also include API activity, where incoming requests will be rejected if they do not adhere to the groups restriction. This solves an important problem for compliance-minded enterprises with an extended approach to access control, covering both UI and API activity. System hooks for project and group member updates System hooks allow for powerful automation by triggering requests when a variety of events in GitLab take place. Thanks to a community contribution, project and group membership changes are now supported in system hooks. This is a terrific addition for those who are looking to build additional levels of oversight and automation over membership changes. Thanks to Brandon Williams for the contribution! S/MIME Email Signing Notification emails sent by GitLab can now be signed with S/MIME for improved security on the instance level. Thanks Siemens, @bufferoverflow, and @dlouzan for the contribution! Omnibus improvements SSL authentication to external Postgres servers is now supported by specifying the certificate in gitlab.rb. GitLab 12.3 includes Mattermost 5.14, an open source Slack-alternative whose newest release includes keyboard accessibility improvements, enhanced Jira integration, and more. This version also includes security updates and upgrade from earlier versions is recommended. Deprecations Users with manually configured .gitlab-ci.yml using Secure features should be aware of deprecations in GitLab 12.3 If you have manually configured your .gitlab-ci.yml configuration file to use DEP_SCAN_DISABLE_REMOTE_CHECKS or DS_DISABLE_REMOTE_CHECKS flag variables, you need to remove this as it is no longer supported. If you utilize vendored templates, your configuration will be kept up to date with variable and argument changes. As announced in GitLab Release 12.0 post Planned removal date: GitLab 12.3 gitlab-monitor tool renamed to gitlab-exporter To prevent confusion with the broader GitLab Monitor feature set, the gitlab-monitor tool has been renamed to gitlab-exporter. gitlab-exporter is a Prometheus web exporter that gives administrators insight into their GitLab instance, whereas the GitLab Monitor features enable monitoring of applications built using GitLab. If youre using Omnibus, youll have to update your gitlab.rb file. Planned removal date: September 22, 2019 Update public projects and subgroups in private groups to private visibility In GitLab 10.0, we introduced a change to clarify the visibility setting of public projects and subgroups in a private group. Since the most restrictive visibility setting applied, attempting to set a project or subgroup to public within a private group resulted in the visibility change being rejected. To prevent errors with existing projects and subgroups with public visibility, all public projects and subgroups in private groups will be updated from public to private in GitLab 12.5. If youd like a less restrictive visibility setting on a particular project or subgroup, you can simply move it out of the private group. Planned removal date: Nov. 22, 2019 GitLab Subscription Plans GitLab is available in self-managed and cloud SaaS options. Self-managed: Deploy on-premises or on your favorite cloud platform. Free: For small teams, personal projects, or GitLab trials with unlimited time. Premium: For distributed teams who need advanced features, high availability, and 24/7 support. Ultimate: For enterprises that want to align strategy and execution with enhanced security and compliance. Cloud SaaS - GitLab.com: hosted, managed, and administered by GitLab with free and paid subscriptions for individuals and teams. Free: Unlimited private repositories and unlimited collaborators on a project. Premium: For teams that need more robust DevOps capabilities, compliance and faster support. Ultimate: Great with many CI/CD jobs. Every public project gets the features of Ultimate for free irrespective of their plan. Cover image licensed under Free ",
        "Gitlab is one of the finest companies out there. Following their progress and seeing them raising $268 million is pretty exciting",
        "The container cleanup effort is welcomed, and I hope the milestone is completed in the near future. My private instance on LXD is using about 350GB, and given that I don't commit large files on Git, I suspect that about 330-340GB is all from the registry. All the latest tagged images probably make up 2GB worth of downloads."
      ],
      "relevant": "true"
    },
    {
      "id": 19881709,
      "title": "GitHub Package Registry",
      "search": [
        "GitHub Package Registry",
        "Normal",
        "https://github.com/features/package-registry",
        "GitHub Packages With GitHub Packages, you can safely publish and consume packages within your organization or with the entireworld. $ echo $PAT | docker login ghcr.io --username phanatic --password-stdin Logged in successfully $ docker tag app ghcr.io/phanatic/app:1.0.0 $ docker push ghcr.io/phanatic/app:1.0.0 1.0.0: digest: sha256:631cb8...fc822c size: 1373 Read developer docs Easy publishing Use industry and community-standard package managers with native tooling commands. Then authenticate and publish directly to GitHub. Trusted sources Understand and safely install package contents. Get packages directly from the community on GitHub, and use only whats been approved for your organization. Speed and security, native toGitHub Use the same secure login for your code and packages Store your packages in the same secure environment as your source code, all protected by your GitHub credentials. Integrate packages with your workflows With a full API and webhooks support, you can extend your workflows to work with GitHub Packages. Get fast and reliable downloads via a global CDN GitHub Packages is built with the latest edge caching via a global CDN to deliver great performance, no matter where your builds run. Packages gives us an automated and secure path to continuous integration and deployment, testing, and delivering products to our customers and users. Shehzan MohammedDirector of Product Management, Cesium As a Yarn maintainer Im excited to see GitHub offer a new package registry solution, and Im looking forward to leverage its capabilities in our future releases. Mal NisonYarn maintainer Since GPR uses the same permissions and security as the rest of GitHub, we can spend less time managing multiple accounts, ACLs and on-premise infrastructure, and more time coding what matters! Chief Information Security OfficerProvidence Health & Services Code to cloud automation Simplify publishing Use Actions to automatically publish new package versions to GitHub Packages. Trigger package installs Run your CI/CD with Actions, and install packages and images hosted on GitHub Packages or your preferred registry of record. Streamline your workflow Use the same GITHUB_TOKEN for all automated package uploads and downloads through Actions. Learn more about GitHub Actions Simple, payasyougo pricing Related resources ",
        "This is really outstanding.<p>It will mean the death of Maven Central, about which I have mixed feelings. On the one hand, Sonatype deserves enormous thanks for what they have done for the open source world, as does mvnrepository.org. Their central repository has been free and maintained for a long time. Thank you, Sonatype.<p>On the other hand, it took me three days to release a new version of one of my artifacts the other day. The process for doing a Maven deploy is very complex. It took hours to get my private key to work because the key registries were slow. Then the staging server was slow, and kept timing out. Support was responsive, and said they were dealing with a DDOS attack. On top of that, it takes a while for artifacts to show up in the registry even after they have been uploaded. I'm glad that getting that artifact out wasn't an emergency.<p>This new Github service separates the registry from the artifact storage, which is the right way to do it. The registry should be quick to update because it's only a pointer. The artifact storage will be under my control. Credentials and security should be easier to deal with. I really hope this works out.",
        "Blog post at <a href=\"https://github.blog/2019-05-10-introducing-github-package-registry/\" rel=\"nofollow\">https://github.blog/2019-05-10-introducing-github-package-re...</a>."
      ],
      "relevant": "true"
    },
    {
      "id": 19226472,
      "title": "Gitlab 11.8 Released",
      "search": [
        "Gitlab 11.8 Released",
        "Normal",
        "https://about.gitlab.com/2019/02/22/gitlab-11-8-released/",
        "GitLab Static Application Security Testing (SAST) scans source code and helps to detect potential security vulnerabilities early in the pipeline. In 11.8, we've added SAST support for JavaScript, building on top of our existing node.js support. Now any JavaScript file can be scanned, like static scripts and HTML. A vital practice in DevSecOps is to scan code changes with each commit, and with this change, we're covering one of the most popular web languages, helping you to find JavaScript risks as early as possible. GitLab Pages got a whole lot better this release, with two key improvements. First, we have introduced GitLab Pages support for projects in subgroups, enabling these projects to easily publish content to the web. GitLab 11.8 also bundles our most popular templates for Pages, so users can get started with just a single click. Application errors provide important insight into the health of your application, and can help detect problems without waiting for users to report them. GitLab 11.8 can now display the most recent errors directly within the project, making them easier and quicker to find and take action on. And many more great features! There are so many great features in this release, that we wanted to highlight a few more: Merge Request Approval Rules: Easily define rules for who needs to approve a change, whether it's a specific user, group, or role. Available on GitLab.com soon, and can be enabled in your own GitLab instance by an administrator. Feature Flags for Environments: Previously, feature flags were either on or off across all of your environments. No more! Feature flags can now be selectively enabled on a per-environment basis. Available on GitLab.com today, and can be enabled in your own GitLab instance by an administrator. Improved Squash Commit Messages: For those who enjoy crafting great commit messages, it can be sad to see them lost in a squashed commit to keep things tidy. On 11.8 squashed commits now automatically utilize the first multi-line commit message, and can also be overridden to make them even better. Join us for an upcoming event This month's Most Valuable Person (MVP) is Aaron Walker Contributor walkafwalka added two new Auto DevOps features this release, support for custom domains and redeployment when only secrets have changed. Thank you for the great improvements! Key improvements released in GitLab 11.8 SAST support for JavaScript Static Application Security Testing (SAST) allows you to spot vulnerabilities in your source code every time you commit a new change to the repository. With this information available in the merge request, you can shift security left and address problems even before they are merged into the stable branch. With 11.8, we add JavaScript to the list of languages supported by SAST. You dont need to change anything in your pipelines. JavaScript projects are automatically detected and analyzed for security vulnerabilities. It is also part of Auto DevOps. Error tracking with Sentry Keeping an eye on errors generated by your application helps maintain a good user experience by detecting problems before users report them and speeding up resolution when they occur. GitLab 11.8 makes it more convenient and efficient to monitor errors by integrating with popular open source error tracker Sentry, and displaying the most recent errors right within your GitLab project. Sentry has recently improved their GitLab integration, enabling detection of suspicious commits, release and commit tracking, and more. With the combination of both integrations youll have a simple path to Sentry from GitLab, as well as a clean way to get to GitLab from Sentry, so that you can always address errors contextually, staying within your existing workflow. Create Pages sites in one click using bundled templates We are now bundling our most popular Pages templates directly in GitLab, opening up the possibility of creating your sites directly from the new project creation screen instead of having to fork a sample repository as before. Check out our blog post about using GitLab Pages templates for more. Pages support for subgroups Pages have been updated to work with subgroups in GitLab, giving you the ability to create Pages sites there as well. Sites set up in this way will have a URL in the format of toplevel-group.gitlab.io/subgroup/project. This will give your projects, even when part of subgroups, access to the ability to create documentation or other sites needed as part of releasing your software. Merge Request Approval Rules Code review is an essential practice of every successful project, but who should review the changes is not always clear. It is frequently desirable to have a variety of reviewers from different teams like Engineering, UX, and Product. Approval Rules, new in GitLab 11.8, allow you to better communicate who should participate in code reviews by specifying the eligible approvers and the minimum number of approvals for each. Approval rules are shown in the merge request widget so the next reviewer can quickly be assigned. In GitLab 11.3 we introduced Code Owners to indicate which team members are responsible for which code in your project. Code owners are integrated into approval rules so that finding the right people to review your change is always easy. Approval Rules are disabled by default in 11.8 and must be enabled by an instance administrator by executing Feature.enable(:approval_rules) in the rails console. Approval Rules have temporarily been disabled on GitLab.com. We expect to be re-enabled after deploying GitLab 11.8.1. Follow this issue for updates. Improved cross-project pipeline triggers Starting with GitLab 9.3, youve been able to create multi-project pipelines by triggering a downstream pipeline via a GitLab API call in your job. In 11.8, weve added first-class support for triggering these downstream pipelines with the trigger: keyword, which can be added to a bridge job to automatically trigger a downstream pipeline when the current pipeline succeeds. Improved squash commit messages Creating Git history that is readable and useful to people in the future can be at odds with pushing small commits to fix a unit test or resolve feedback. Commit squashing combines all these commits into a single tidy change, but at the same time wipes out your thoughtful commit messages. GitLab now defaults the squash commit message to the first multi-line commit message in the feature branch, and allows you to override the commit message so that you can update it to reflect any important changes. Auto DevOps support for environment-specific custom domain Auto DevOps allows you to quickly get started by adding a base domain for your projects. When your application is ready for production deployment, you may then want to use a custom, fully qualified domain name. You can now use the environment variable ADDITIONAL_HOSTS to specify one or more custom domains for your application. Furthermore, you can scope it to a specific environment by prepending the environment name to the variable, ie. <ENVIRONMENT>_ADDITIONAL_HOSTS. Thank you Aaron Walker for the contribution! Show function scale for Knative functions Deploying functions using GitLab Serverless comes with all the benefits of Knative, such as scaling your serverless deployments up and down to zero. You can now see the scale of your serverless deployments for each application or function deployed to your Knative instance. Scale is illustrated by the number of Kubernetes pods currently in use. Other improvements in GitLab 11.8 Specify the first day of the week Before, calendars in GitLab assumed that weeks began on Sunday. Users can now elect in their profile preferences to have their first day of the week begin on Monday, which is reflected throughout the application in date pickers and contribution graphs. Thank you Fabian Schneider for the contribution! Authenticate credentials from a smart card with LDAP Organizations using smart cards as authentication tokens frequently use LDAP for centralized identity management. In 11.8, were iterating on the smart card authentication added in 11.6 by allowing credentials on a smart card to be authorized against a configured LDAP server. GitLabs approach follows RFC4523 schema standards using the certificateExactMatch rule. Upgrade Kubernetes Runner application via Kubernetes integration Keeping your Kubernetes-deployed apps running on the latest version ensures you have the newest features as well as up-to-date security. GitLab 11.8 allows you to upgrade the GitLab runner running in Kubernetes with a single click. Future releases will include similar functionality for the rest of the applications. Record of a users last activity in GitLab now includes browsing GitLab includes a user attribute, last_activity_on, to help admins understand when a users last activity was taken. This is very helpful for finding active and inactive users. To ensure were capturing read-only activity, weve expanded last_activity_on to update on visits to pages related to dashboards, projects, issues, and merge requests. Search repository tags in a project via the API You can now search for repository tags in a project via the Tags API. This makes finding a specific tag in a project more straightforward; if youre looking for related projects that match a specific version tag, youre now able to find matching projects with ease. Thank you Robert Schilling for the contribution! Improved group overview with reduced white space In 11.8, weve made the group overview more information dense with a redesign. Weve reduced the amount of whitespace on this page and aligned the user experience with the project overview redesign. This is the first iteration of a larger set of improvements to the group overview page, and were excited to continue iterating on this page. Weve restyled the related merge requests section in an issue, to bring visual consistency to related issues and improve aesthetic appearance. Were even adding more metadata to each row in the design in a future release, to help users see relevant merge request information even more quickly and in context. Manage group labels via the API You can now manage group labels via the API, similar to project labels, helping further support customized planning and execution workflows on your teams. Thank you Robert Schilling for the contribution! Predefined Pages variables in CI CI_PAGES and CI_PAGES_URL have been added as CI variables for Pages pipelines, giving you visibility into the Pages domain name and URL. This allows for more flexibility when working with Pages sites hosted in multiple locations. Gitaly support for TLS Gitaly now supports TLS, which means all communication between GitLab and Gitaly will be encrypted when TLS is enabled. Previously, communication between GitLab and Gitaly was not encrypted, but relied on the security of the network. Jump to file in merge request diff Reviewing large merge requests can be difficult, particularly jumping from one file to another. The new fuzzy file finder makes moving from one file to another painless, so that you can quickly navigate the diff using your keyboard. Receive alerts from manually configured Prometheus instances In GitLab 11.3 support for setting alerts was introduced, however it was limited to Prometheus instances which were deployed through the GitLab Kubernetes integration. With GitLab 11.8, manually configured Prometheus servers can now also notify GitLab of alerts, by simply adding GitLab as a webhook receiver in alertmanager. After receiving an alert, GitLab will email Maintainers and Owners of the project. Confidential issues for security vulnerabilities Users can create a new issue to address and remediate security vulnerabilities from the security reports in a merge request, in the pipeline view, and in the Security Dashboard. This information contains sensitive data that may disclose confidential details that should not be disclosed before a fix is available and released. Starting with GitLab 11.8, issues created from a vulnerability are marked as confidential by default, and users can turn the flag off when the information can be disclosed. Display cluster environment in serverless function list view The Serverless page has been improved and will now group functions deployed to Knative based on the cluster environment they are deployed to. In addition, function description is now displayed along with shortcut button to copy the function endpoint and another open the endpoint in a new tab. Scroll roadmap forward into the future and backward into the past When you first load the roadmap view, GitLab preselects a time period for you, with options to select weekly, monthly, or quarterly intervals. But the view was fixed, and epics outside of what was displayed were hidden. With this release, you can now scroll forward into the future and backward into the past. Epics that fall in these expanded times will automatically appear in the view, without requiring you to refresh the page in any way, allowing you a seamless experience to see even more epics in as long of a timeline you need. Feature Flags for Environments It is now possible to individually turn feature flags on or off on a per-environment basis. The behavior of your feature flags is controlled by creating a set of rules based on matching the environment name. There is always a default wildcard rule (*), but you are also able to add more rules by adding more environment specs (for example, review/*). In 11.8.0 this feature will require enabling the feature flag, by executing Feature.enable(:feature_flags_environment_scope) in the rails console. User activity and creation dates shown in admin panel Understanding the activity level of users in GitLab should be an easy task for instance administrators. To help, weve added user creation date and the date of a users last activity to the Users area of the admin panel at /admin/users. You can read more about the types of actions GitLab considers activity here. Project tags are now project topics Project tags are a useful way to organize related projects, but the term tag collided with Git tags. To resolve this, weve renamed project tags to project topics and improved their presentation on the project overview page. Were excited to make topics more useful for project discoverability, and are adding topic filtering to the project dashboard in 11.9. Improved project lists with more information density Weve responded to user feedback on our first project list redesign by improving the information density on this page with an additional column and less whitespace. Child Epics in Epics API In our previous release, we launched child epics, the ability to attach epics to epics. With this release, you can now manage these epic relationships via the API as well. So you can now manage customized workflows in your teams, especially through automation. Move Auto DevOps domain from CI/CD settings to cluster settings Specifying a base domain for Auto DevOps allows you to take advantage of powerful features such as Auto-Review Apps and Auto-Deploy. Weve now made it even easier to specify the base domain by moving it directly to cluster settings. This will make it simple to define the base domain when the cluster is created, and also to define different domains for different clusters. .html extensions are now automatically resolved for Pages sites A file in your Pages site called /sub-page.html can now also be accessed as /sub-page, giving you more options over how your site appears to your users. Add tolerations to Kubernetes executor Kubernetes provides an exciting opportunity to disconnect the underlining hardware from where our workloads run. However, some tasks require specialized hardware including jobs that may require more resources than others. Kubernetes supports this by introducing taint and toleration to nodes in order to include these considerations when scheduling pods. Weve added native support for taints and tolerations in the Kubernetes executor in GitLab Runner to support these types of workflows. Gitaly support for Elasticsearch Previously, you had to use NFS to talk to Git in the filesystem if you were using Elasticsearch. With this release, you can use Gitaly instead of NFS, improving Git access performance. Approval counts in the merge request list Merge requests that are approved and ready to merge can now be spotted easily from the merge request list. The number of approvals required and number of approvals received is now shown in the merge request list. Thank you Andy Steele for the contribution! Clean up unused tags from the Container Registry using the API Many organizations build containers on every commit, to facilitate validation of code changes, as well as final deployment. This can lead to a large number of container tags that are used for a short period of time, and are no longer necessary. GitLab 11.8 now allows end users to clean up their container registries using our API, by deleting tags singly or in bulk using a regex. Force re-deploy when Auto DevOps application secrets are updated When you configure an app secret for Auto DevOps using the K8S_SECRET_ variable syntax, a matching Kubernetes secret will be created for your application. When these app secrets are updated, Auto DevOps will redeploy your application with the updated secrets. Thank you Aaron Walker for the contribution! Ensure Cert-Manager works with Auto DevOps URLs Cert-Manager provides an easy way to add HTTPS support for your Auto DevOps applications. This release adds support for URLs longer than the default 64 characters supported by Lets Encrypt, providing more flexibility for your applications. Omnibus improvements GitLabs docker-distribution-pruner is now bundled with Omnibus, allowing administrators a method to clean up registry storage. GitLab 11.8 includes Mattermost 5.7.1, an open source Slack-alternative whose newest release includes several user experience improvements. This version also includes security updates and upgrading is recommended. node_exporter no longer runs by default in the Omnibus docker image, as it requires access to the host. Additional alerts have been added, notifying administrators about: high unicorn utilization, sidekiq job queues, postgres deadlocks, high error rates, and more. nginx has been updated to 1.12.2, registry to 2.7.1, and gitlab-elasticsearch-indexer to 1.0.0. prometheus has been updated to 2.6.1, node_exporter to 0.17.0, and redis_exporter to 0.26.0. Deprecations Ruby 2.5 required Beginning with GitLab 11.6, Ruby 2.5 is required to run GitLab. Omnibus GitLab and the GitLab Chart already ship with Ruby 2.5.3, but users of source installations that run Ruby 2.4 will have to upgrade. Planned removal date: Dec. 22, 2018 Raspbian Jessie support GitLab 11.8 is the last release with support for Raspbian Jessie. Jessie has transitioned to LTS, and the latest Raspbian Jessie image is over a year old. We recommend that users upgrade to Raspbian Stretch. Planned removal date: Feb. 22, 2019 Google OAuth2 SSO only supported in GitLab 11.7+ On Mar. 7, 2019, Google is shutting down all Google+ APIs. You can read more about the announcement from Google here. Since GitLab versions prior to 11.7 rely on these APIs for Google OAuth2, Google single sign-on will no longer function on these versions. GitLab 11.7 and beyond will support Google SSO. If your instance relies on Google OAuth2 for authentication, we recommend upgrading to 11.7. Planned removal date: Mar. 7, 2019 Developers can delete Git tags in GitLab 11.9 Removing or modifying release notes for Git tags on non-protected branches has been historically restricted to Maintainers and Owners. Since Developers can add tags as well as modify and remove non-protected branches, Developers should be able to remove Git tags as well. In GitLab 11.9, were making this change to our permissions model to improve workflow and help developers make better and more effective use of tags. If youd like to continue to restrict this permission to Maintainers and Owners, you can make use of protected tags. Planned removal date: Mar. 22, 2019 Hipchat integration Hipchat will be discontinued. So we are removing the existing GitLab Hipchat integration feature as part of the 11.9 release. Planned removal date: Mar. 22, 2019 CentOS 6 support for GitLab Runner using the Docker executor Runner support for CentOS 6 when using the Docker executor will be removed in GitLab 11.9 because we are updating to a more current Docker library which no longer supports CentOS 6. Please see this issue for additional details. Planned removal date: Mar. 22, 2019 Removal of the System Info section in the admin panel GitLab presents information about your GitLab instance at admin/system_info, but this information can be inaccurate. Were removing this section of the admin panel in 11.10, and recommend using other monitoring capabilities. Planned removal date: Apr. 22, 2019 GitLab.com Pages domains that are not validated will be removed after one week In order to improve performance of GitLab.com, domains that are not able to be validated will be deleted after one week (the validation will be tried for four days before the one-week countdown starts.) If you are relying on holding the domain with GitLab without having done validation, you will now need to complete that step in order to ensure that the domain remains registered with you. Please see the instructions on how to validate your domain to ensure you do not run into any issues. If your GitLab.com Pages domain is not serving 404 errors, then it is already validated. See gitlab-ce#44696 for details on the plan for cleanup. Planned removal date: Apr. 22, 2019 Support for Prometheus 1.x in Omnibus GitLab With GitLab 11.4, the bundled Prometheus 1.0 version is deprecated in Omnibus GitLab. Prometheus 2.0 is now included, however the metrics format is incompatible with 1.0. Existing installations can upgrade to 2.0 and optionally migrate their data using an included tool. With GitLab 12.0, any installation not yet running Prometheus 2.0 will be automatically upgraded. Metric data from Prometheus 1.0 will not be migrated, and will be lost. Planned removal date: Jun. 22, 2019 TLS v1.1 will be disabled by default in 12.0 Beginning with GitLab 12.0, TLS v1.1 will be disabled by default to improve security. This mitigates numerous issues including Heartbleed and makes GitLab compliant out of the box with the PCI DSS 3.1 standard. To disable TLS v1.1 immediately, set nginx['ssl_protocols'] = \"TLSv1.2\" in gitlab.rb and run gitlab-ctl reconfigure. Planned removal date: Jun. 22, 2019 OpenShift template for installing GitLab The official gitlab helm chart is the recommended method for operating GitLab on Kubernetes, including deployment on OpenShift. The OpenShift template for installing GitLab is deprecated, and will no longer be supported in GitLab 12.0. Planned removal date: Jun. 22, 2019 GitLab Geo will enforce Hashed Storage in GitLab 12.0 GitLab Geo requires Hashed Storage to mitigate race conditions on secondary nodes. This was noted in gitlab-ce#40970. In 11.5, we added this requirement to the Geo documentation: gitlab-ee#8053. With 11.6, sudo gitlab-rake gitlab:geo:check checks that Hashed Storage is enabled and all projects are migrated: gitlab-ee#8289. If you are using Geo, please run this check and migrate as soon as possible. In 11.8, a permanently dismissable warning will be displayed on the Admin Area Geo Nodes page if the above checks are not resolved: gitlab-ee!8433 In 12.0, Geo will enforce the Hashed Storage requirement: gitlab-ee#8690. Planned removal date: Jun. 22, 2019 GitLab Subscription Plans GitLab is available in self-managed and cloud SaaS options. Self-managed: Deploy on-premises or on your favorite cloud platform. Free: For small teams, personal projects, or GitLab trials with unlimited time. Premium: For distributed teams who need advanced features, high availability, and 24/7 support. Ultimate: For enterprises that want to align strategy and execution with enhanced security and compliance. Cloud SaaS - GitLab.com: hosted, managed, and administered by GitLab with free and paid subscriptions for individuals and teams. Free: Unlimited private repositories and unlimited collaborators on a project. Premium: For teams that need more robust DevOps capabilities, compliance and faster support. Ultimate: Great with many CI/CD jobs. Every public project gets the features of Ultimate for free irrespective of their plan. Cover image licensed under Unsplash ",
        "You know, there was a thread the other day about a new release announcement for some IDE.  It was quickly removed, on grounds that the Hacker News FAQ says you shouldn't repost something \"<i>If a story has had significant attention in the last year or so</i>\".<p>I remember thinking that it was a real stretch to interpret different release announcements, separated by months, as \"duplicate\" posts.  But this was coming from dang himself, so I guess that's the authoritative view.<p>Just pointing out that Gitlab operates on a more or less monthly release cadence.  Pretty much every release gets an announcement thread on HN's front-page for the full day.  And usually there's a separate front-page thread or two in between, to announce stuff in upcoming releases.  I've never once seen any of this removed, or even questioned.",
        "Overview of the three main improvements in this release:<p>1. JavaScript coverage in SAST<p>GitLab Static Application Security Testing (SAST) scans source code and helps to detect potential security vulnerabilities early in the pipeline. In 11.8, we've added SAST support for JavaScript, building on top of our existing node.js support. Now any JavaScript file can be scanned, like static scripts and HTML. A vital practice in DevSecOps is to scan code changes with each commit, and with this change, we're covering one of the most popular web languages, helping you to find JavaScript risks as early as possible.<p>2. GitLab Pages for subgroups and templates<p>GitLab Pages got a whole lot better this release, with two key improvements. First, we have introduced GitLab Pages support for projects in subgroups, enabling these projects to easily publish content to the web. GitLab 11.8 also bundles our most popular templates for Pages, so users can get started with just a single click.<p>3. Error Tracking with Sentry<p>Application errors provide important insight into the health of your application, and can help detect problems without waiting for users to report them. GitLab 11.8 can now display the most recent errors directly within the project, making them easier and quicker to find and take action on."
      ],
      "relevant": "true"
    },
    {
      "id": 19540845,
      "title": "Git implemented in Rust",
      "search": [
        "Git implemented in Rust",
        "Normal",
        "https://github.com/chrisdickinson/git-rs",
        "git-rs Implementing git in rust for fun and education! This is actually my second stab at it, so big blocks will land in place from my first attempt. I'm trying again this year after reading more of \"Programming Rust\" (Blandy, Orendorff). TODO Read objects from loose store Read objects from pack store Read packfile indexes Read delta'd objects Fix interface so we don't need to run open for each read() BUG: certain OFS deltas are misapplied. Isolate the error case Fix it Load refs off of disk Parse git signatures (\"Identity\"'s) Create iterator for walking commit graph Create iterator for walking trees Materialize trees to disk (post gitindex?) Create index from packfile Rename Storage trait to Queryable Rework object loading API from <Type + Boxed reader> to \"we take a writable object\" Carry the rework out through StorageSet Create the index Wrap it in a nice API refs v2 Load refs on demand Load packed-refs .git/index support Read git index cache Write git index cache Create interface for writing new objects Add benchmarks Create packfile from list of objects (API TKTK) Network protocol receive-pack send-pack Try publishing to crates Write documentation Use crate in another project PLAN 2019-02-08 Update It's been a minute! As you might have seen, figuring out packfile indexing has forced a lot of changes on the repo. There's now a src/pack/read.rs file that holds generic read implementations for any BufRead + Seek. The signature of the Storage trait changed -- instead of returning a boxed read object, it now accepts a Write destination. Further, Storage is now Queryable (a better name!). Because we moved from returning a Box to accepting generic Write, we could no longer box Queryables. I didn't know this about Rust, so TIL! StorageSet objects had to be rethought as a result -- they could no longer contain Box'd Storage objects. Instead, we put the compiler to work -- because storage sets are known at compile time, I implemented Queryable for the unit type, (), two types (S, T), and arrays of single types Vec<T>. This means that a StorageSet may hold a single, top-level Queryable, which might contain nested heterogenous Queryable definitions. It gives me warm, fuzzy feelings You might also note that we're not actually done indexing packfiles. Here's the sitch: in order to create a packfile index, you have to run a CRC32 over the compressed bytes in the packfile. The ZlibDecoder will pull more bytes from the underlying stream than it needs, so you can't take the route of handing it a CrcReader and get good results. It's got to be a multi-pass deal. The current plan is: run one pass to get offsets, un-delta'd shas and types. Run a second pass to resolve CRCs and decompress deltas. This can be done in parallel. 2019-01-23 Update It's time to start indexing packfiles. This'll let us start talking to external servers and cloning things! However, it's kind of a pain. Packfiles (viewed as a store) aren't hugely useful until you have an index, so I had designed them as an object that takes an optional index from outside. My thinking was that if an index was not given, we would build one in-memory. That just blew up in my face, a little bit. In order to build an index from a packfile you have to iterate over all of the objects. For each object, you want to record the offset and the SHA1 id of the object at that offset. However, the object might be an offset or a reference delta. That means that in order to index a packfile, you've got to be able to read delta'd objects at offsets within the packfile (implying you already have the Packfile instance created) and outside of the packfile ( implying you have a StorageSet.) In other words: my assumptions about the program design are wrong. So, in the next day or so I'll be reversing course. It should be possible to produce a Packfile as a non-store object and iterate over it. The \"store\" form of a packfile should be the combination of a Packfile and an Index (a PackfileStore.) This means I'll be splitting the logic of src/stores/mmap_pack into \"sequential packfile reads\" and \"random access packfile reads (with an index.)\" It's fun to be wrong 2019-01-21 Update Well, that was a fun bug. Let's walk through it, shall we? This occasionally showed up when a delta would decode another delta'd object. I found a hash that would reliably fail to load. We'd fail the read because the incoming base object would not match the 2nd delta's \"base size\". Here. Removing the check to see if I got the deltas wrong would cause the thread to panic -- the delta's base size wasn't a lie. First, I switched back to my old mmap-less packfile implementation, because I recently touched that code. \"Revert the thing you touched last\" is a winning strategy in these cases: doesn't cost expensive thinking, quickly puts bounds around the bug. Alas, the old packfile implementation also had this bug. No dice. I compared the output of this git implementation to my JS implementation. I confirmed that the output of the JS implementation worked by comparing its output for the hash of concern to vanilla git. After confirming that, I logged out the offsets being read from the file and the expected sizes. I compared this to similar debugging output I added to git-rs. The offsets are the bound values sent into the packfile. For the outermost read (\"Give me the object represented by eff4c6de1bd15cb0d28581e4da17035dbf9e8596\"), the offsets come from the packfile index. For OFS_DELTA (\"offset delta\") types, the start offset is obtained by reading a varint from the packfile and subtracting it from the current start offset. The offsets and expected sizes matched! This meant that: I was reading the correct data from the packfile I was reading varints correctly The bug must be in the application of the delta to a base object From there I added logging above these state transitions, noting the particulars of the operation. I added the same logging to the JS implementation, and found that (aside from totally bailing out ahead of the 2nd delta application) the commands were the same. So it wasn't even that my delta code was wrong: it was my Read state machine. At this point, I was like: \"This is a read state machine bug. I know this.\" So, one of the things this state machine does is carefully bail out if it can't write all of the bytes for a command. (\"If there remains an extent to write, record the next state and break the loop.\") However, at this point we've already consumed the last command. There are no more instructions. So if this function were to be called again, ... We would politely (but firmly) tell the caller to buzz off (written == 0, here.). The fix turned out to be simple, as these fixes usually are. (I need to write a test for this, I know. I know. Pile your shame on me.) So what did we learn? Always test your state machines, folks. (I've said it once, and I'm saying it again.) Malleable reference implementations will save your bacon. Make sure you can trust your reference implementation. Anyway. The tree reader works now! 2019-01-19 Update It's slightly faster! mmap sped things along nicely, shaving 20ms off of our runtime. We're still reliably slower than git, though. It might be because we load the refset immediately. I kept the immutable \"file per read\" packfile store around; I think it may come in handy in the future. It would be excellent to capture this as a benchmark instead of running it ad-hoc. I integrated the tree walking iterator and got a nice surprise: There's a bug in my OFS delta code! This is interesting, because it only appears for certain blobs in certain repositories. Otherwise other OFS deltas seem to resolve cleanly. Case in point: many of the commits I load as a test of the commit walk-er are OFS-delta'd. Also of note: I've split from src/bin.rs into dedicated binaries for tree walking and commit walking. Today's theme: isolate the bug in a test case. EOD Update: It's really helpful to have a reference implementation. I've confirmed that the reference implementation can read the object that breaks this project. We are reading the same offsets, as well (phew) I've further confirmed that swapping out the packfile implementation for the older, slower packfile doesn't affect anything. I suspect this means there's either a problem in my delta code (highly possible!), my varint decoding code (very possible), or the Read implementation for Deltas. Yay, narrowed down results! 2019-01-15 Update I added an (experimental) git_rs::walk::tree iterator to take a Tree and yield a path + a blob for each item. It's probably slower than it should be: for each item it has to clone a PathBuf, because I couldn't work out the lifetimes. If you know how to fix that, please open an issue and let me know I took some time to clean up the warnings during builds. Oh! I also installed Clippy which warns about higher level antipatterns in Rust! I'm still noodling over the 2-3x slowdown between vanilla git and Our Git. I think I might create two packfile interfaces -- one \"generic\" and one \"mmap\"'d, to see if one or the other makes up the difference in performance. This also has the virtue of being unsafe code, which is something I have not yet used in Rust! 2019-01-06 Update I wrote an iterator for commits! The first cut kept a Vec of (Id, Commit) around, so we could always pick the most recent \"next\" commit out of the graph (since commits may have many parents.) But in finishing up the collections section of \"Programming Rust\" I noticed that BinaryHeap was available, which keeps entries in sorted order. You don't often get to choose the underlying storage mechanism of your collections in JS, so this hadn't occurred to me! Anyway. I swapped out the Vec for a BinaryHeap in this commit. Because this pushes the ordering into an Ord impl for a type, this opens up the possibility of using the one iterator definition for multiple different orderings. Neat! Testing against a couple long-lived repo, the results coming out of git_rs are exactly the same as git! However, it takes about twice the time: 60ms for git_rs where git takes 30ms. I think I have a lead on this, and it has to do with packfile stores: each read from a packfile opens a new File instance. I've added a TODO section to keep track of what comes next! 2019-01-02 Update I implemented ref loading. It was a bit of a pain! Translating to and from Path types took a bit of doing. I've been trying to read up on Rust idioms -- I found a couple of resources: The Rust API Guidelines doc has been very helpful. @mre's idiomatic rust repo collects many interesting links. I've also been idly checking out videos from RustConf 2018 As a result, I've implemented FromStr for Id, (hopefully) giving it a more idiomatic API -- let id: Id = str.parse()? 2018-12-27 Update Rust is feeling more natural. This chain felt natural to write. I was even able to cross-index a list with only a minimum of fighting the borrow checker. I split the objects interface into Type + boxed read with a method for reifying the data into an Object. This feels good! It lets folks check to see, for example, if they're referring to a Blob without having to load the entire Blob into memory. The closure interface for the loose interface works pretty well, but pack interfaces need to be able to ask the overarching set of stores for a reference due to REF_DELTA objects. This is a bummer, because it really quickly turns into \"fighting the borrow checker.\" Right now I think the way forward is to build a StorageSet that holds a Vec of heterogenous Box<Storage> objects, where Storage is a new trait that specifies get(&Id, &StorageSet). A sidenote re: the loose store: it feels kind of odd to have to produce a git_rs::Error instead of a std::io::Error. Room for improvement! Oh! It was pretty easy to add a binary to this lib crate. And now we can git log other repos! 2018-12-21 Update Decided to focus on moving a bit slower and making sure I have tests for primitives this time around. Moved away from my original Box<Write> trait object design for object instance reading & storage format in favor of generics. ",
        "I love to see people reimplementing existing tools on their own, because I find that to be a great way to learn more about those tools. I started on a Git implementation in Rust as well, though I haven't worked on it in a while: <a href=\"https://github.com/avik-das/gitters\" rel=\"nofollow\">https://github.com/avik-das/gitters</a>",
        "If you're interested in this, you may enjoy \"Building Git\" by James Coglan - a comprehensive book that takes you through reimplementing git in Ruby.<p><a href=\"https://shop.jcoglan.com/building-git/\" rel=\"nofollow\">https://shop.jcoglan.com/building-git/</a>"
      ],
      "relevant": "false"
    },
    {
      "id": 20478156,
      "title": "Gitlab: 2019 Developer Report",
      "search": [
        "Gitlab: 2019 Developer Report",
        "Normal",
        "https://about.gitlab.com/developer-survey/2019/",
        "For the fourth year in a row, we asked DevOps teams to tell the truth about their practices and processes, their challenges and their careers. Download the report In the midst of a global pandemic and a new way of working, DevOps teams got serious about what matters most. Our 2021 Global DevSecOps Survey found sharp increases in automation, release cadences, continuous deployments, and security postures, as well as a growing reliance on cutting edge technologies, including artificial intelligence and machine learning. Nearly 4,300 people shared their struggles and successes, and demonstrated a commitment to DevOps maturity like weve never seen before. Download the survey results Developers A full 60% of devs are releasing code 2x faster than ever before, thanks to DevOps. And in the last year, developers definitely went big: Rather than focusing on incremental improvements, devs brought high impact technologies into their process including source code management, CI/CD, a DevOps platform, and automated testing. Whats still challenging? Testing (not enough, too late in the process, insufficient automation) and code reviews (too little, too late, take too long). And developers have a long list of process improvements from AI/ML to performance optimizations theyd like to have time to tackle. Read the entire survey Security In a dramatic sign of progress, 72% of security pros rated their organizations security efforts as either good or strong. DevOps teams are certainly running more security scans than ever before: over half run SAST scans, 44% run DAST, and around 50% scan containers and dependencies. And 70% of security team members say security has shifted left. But, old habits die hard when it comes to friction with developers. Although the percentage of security pros frustrated with developer behaviors around bugs has decreased substantially, true harmony remains a way off over three-quarters of the security team continue to think devs find too few bugs too late in the process. Download the survey Operations On the ops side, automation is happening: 56% reported their teams are either fully or mostly automated. And changes are happening too devs are taking on more traditional ops tasks, like provisioning, while the operations team is either managing cloud services or focused on infrastructure or hardware. And the future is shifting too: A slim majority of ops pros think advanced programming will be the most important skill for their future careers, an interesting direction for this role. Take a deep dive into our 2021 DevSecOps survey results and see how you compare. Download the survey Curious what nearly 4,300 people had to say? Download the Report Git is a trademark of Software Freedom Conservancy and our use of 'GitLab' is under license View page source Edit in Web IDE please contribute. GitLab B.V. ",
        "Here is the link to the report: <a href=\"https://about.gitlab.com/resources/downloads/2019-global-developer-report.pdf\" rel=\"nofollow\">https://about.gitlab.com/resources/downloads/2019-global-dev...</a>",
        "> Fully 61% of companies say GitLab is their most used tool for CI and build<p>a survey by gitlab is biased towards gitlab, how strange"
      ],
      "relevant": "true"
    },
    {
      "id": 19989631,
      "title": "Dependabot is joining GitHub",
      "search": [
        "Dependabot is joining GitHub",
        "Normal",
        "https://dependabot.com/blog/hello-github/",
        "Dependabot has been acquired by GitHub and we couldn't be more excited! Here's what you need to know: We're integrating Dependabot directly into GitHub, starting with security fix PRs You can still install Dependabot from the GitHub Marketplace whilst we integrate it into GitHub, but it's now free of charge We've doubled the size of Dependabot's team; expect lots of great improvements over the coming months It's a dream outcome for us at Dependabot, and we can't wait to bring automated dependency updates to millions of GitHub users. If you're an existing Dependabot customer, the changes you'll notice are: Dependabot is now free. You'll no longer be billed for it, and if you paid for future months, we'll be in touch to refund you. In time, you'll be able to configure Dependabot within GitHub, so you'll no longer need the Dependabot dashboard. Thank you for making Dependabot what it is today. Your feedback, bug reports and encouragement over the last two years have been invaluable. We couldn't have built Dependabot without you. Grey, Harry and Philip Questions you may have What is happening to the existing Dependabot product? The existing Dependabot app has been renamed to \"Dependabot Preview.\" It will remain available in the GitHub Marketplace, fully supported and now free of charge, whilst we integrate its features directly into GitHub. Can new users still sign up? Yes! If you're not already a Dependabot user, we encourage you to give \"Dependabot Preview\" a try. We'll use your feedback on it to inform the integration with GitHub. Whats happening to my paid membership? Dependabot is now free. You'll no longer be billed for it, and if you paid for future months, we'll be in touch to refund you. Will there be any changes to Dependabot's privacy policy? We're not planning to make any changes to Dependabot's privacy policy. Will dependabot-core remain open source? Dependabot Core is currently source available and hosted here. It will remain source available, with a license in keeping with the intention in the project's README. ",
        "Curious about the side effects of this.<p>Imagine you had an open source project that was just something on the side or you worked on in a different life. And then you see pull requests for updates and decide to fix a bug here or there. And then maybe it prompts you to recommit to it.<p>If that were to apply to even a tiny percentage across all of Github could have major implications for open source as a whole.",
        "Edit: copy/pasting my more extensive comment from the Sponsors thread.<p>All the recent additions to Github are superficially very nice and convenient features (Actions, package registry, Sponsors, Dependabot).<p>But they represent a very significant change in mindset. Github is turning from a neutral code hosting platform with a myriad of equally empowered third party integrations into the direction of a \"all in one\" dev tool and platform.<p>I understand the internal pressures to do this: increased popularity, added value proposition for customers, more revenue.<p>But: all the built-in tools will have an inherent advantage over third party solutions. This inevitably leads to increased lock-in and homogenization.<p>I was very critical of the Microsoft acquisition for similar reasons, and considering the monumental role Github represents for open source today, I am very sceptical of the way things are going.<p>We might very well regret centralizing everything open source around Github in a few years."
      ],
      "relevant": "true"
    },
    {
      "id": 19276113,
      "title": "Redesigning GitHub Repository Page",
      "search": [
        "Redesigning GitHub Repository Page",
        "Normal",
        "http://tonsky.me/blog/github-redesign/",
        "Illustration by Yulia Prokopova Github design is pretty good: it gets the job done, its clean, has consistent visual language, its design is calm and suitable for everyday use. Given all that, there are still many areas that could be improved. Today well take one interfacerepository pageand look what UI problems it has and if we can fix them. First problem: nested tabs Lets start with the biggest issue right away: information architecture. Take tabs. Currently therere two levels of tabs, one nested under the other: If you are a programmer, you might be surprised but other people normally dont like hierarchies. Nested structures are hard to grasp, remember, navigate, and grouping is very often non-intuitive. Nested tabs are one of the worst UI patterns out there. Then theres a plain usability issue: lets say Im in Wiki and need to see Releases. What should I do? Theres no Releases tab visible, so I must figure out somehow that Releases are part of the Code (?). That makes almost no sense. Releases are as much part of the Code as Issues or Wiki are. Solution here is to flatten all tabs into a single navigational control: Organized that way, tabs are immediately accessible from anywhere in the repo. This is a big deal. As a bonus, we also won quite a bit of vertical space without sacrificing anything! Vertical space is very important, it lets you see more content and get to it fasterall good things. We still have one problem though: tabs dont fit. Were going to solve it by removing icons, but let me build up a case for that first. Problem 2: Redundant icons Icons are visual cues that help you scan the UI quickly. Quickly here means faster than reading text labels. If for some reason reading labels is still faster then icons arent working. One example of icons misuse: if you put too many icons in a row and they are all different, they wont work. Prioritizing, or highlighting, something means deprioritizing everything else. You cant highlight everything. Another way to fail at icons: if you use obscure graphics, people will have to read labels anyways, so, again, not working. Now lets be honest: the domain of repository and project management is pretty abstract. No matter how good you are at design and how hard you try, you wont come up with a great icon for a commit. Or a release. Or an issue. Or a license. A great icon is something other people know and understand. And for repositories, theres simply none. I mean, So Github tab icons are purely decorative. If you dont believe me, look at what Github itself is doing. They dim icons: Thats a sure sign that they, too, think its near impossible to figure out why backward clock means Commit. Github knows people will be looking at the labels anyways. But even being decorative, theyre bad at it. I mean, Icon + Label + Counter make for a symmetric and weak composition: By removing icons we: free up a lot of horizontal space, make design stronger, and get rid of visual noize. Win-win-win! Heres the result, tabs without icons: Test yourself, see if you can find Releases tab without an icon and if it was harder than before? It wasnt, was it? A note on this design: I am using the same limitations Github already uses: English language only, locked page width of 1020px. For different conditions, say, for the adaptive design we might want a different solution. Another note: I had to remove Contributors tab (which was actually not a tab, but a sub-tab from Insights that was duplicated in Code for some reason) to accommodate for Settings tab. Dont worry, well get Contributors back later. Problem 3: Vanity counters This is the vanity menu: The thing with vanity metrics is that there should be just one. One metrics is simple to understand and focus. Two or three split attention, making everything weaker. Luckily for us, both watchers and forks perform poorly as metrics anyways. For watches, people tend not to watch too much. For forks, people tend to fork for no reason. But stars work. They work because they have no other function but to represent vanity. So lets keep stars and move them to the left to get more attention: Problem 4: Watch button ambiguity In the watch button we have a classic button or status UX dilemma. Buttons tell us what can be done but dont say what the current status is. Status tells current state but its not clear what it would change to. In Github case Watch has a button label but it doesnt act as a button: clicking on it wont make you watch the repo. Its not a status either: if you see Watch it means you are not watching. Same for the other two states: they are neither buttons nor states. The problem here is that a single button cant be used to switch between three states. But dropdown can! Dropdowns are a well-established UI component that shows status and can be used to change it at the same time. Funny, but Github is already using a dropdown! We just need to fix it to work as any other dropdown on Earth works: to show current status. Trivial fix, really: Minor, but annoying: that checkmark is really hard to spot. Lets highlight the whole row: All together so far: Uff, weve done a lot! If you need a little break, now would be a perfect time for it. Dont worry, Ill wait. Back? Great! Lets move on. Problem 5: Repo description This is the repository description: The problem with it is: why is it located under the Code tab? Its a description of the whole repository, not just its code, right? To fix this lets move it above the tabs, to the area that belongs to the whole repository: It still needs a couple of touches. First, font is neither big nor small (its 16px, standing between 18px repository name and 14px tabs). Lets make it 14px so that therere only two distinct font sizes. Also Im sure theres no need to render https:// in the URL: The second change is to move topics right next to the repository name. Therere usually just a few of those, so it seems wasteful to dedicate a whole line to them: Look at us, winning more vertical space again! Problem 6: Removing background color Blue topics on blue background became harder to read. This is because they used to be on #FFF and now theyre on Githubs #FAFBFC very light dirty blue. Lets change tabs background to #FFF too: But why was that background there in the first place? What did it do? My guess is Github had to add it because the structure of their menu layers was becoming too complex and they needed visual cues to help you split it in order to understand. The black top bar serves the same purpose: to separate. I mean, they were literally spending a good half of 768px screen at navigation alone. When split into layers, at least you are not immediately scared by it. Without a background, it would be a mess. But because we simplified the whole header so much and removed one intermediate layer, we dont need that color coding anymore. Instead, we can enjoy fresh crisp white: And look at all that free space! Finally, we can see some content in the top half of the screen too. Problem 7: Description editing A small touch. If you own the repository, you get to edit both its description and its topics: First, the Edit button is badly misplaced too far, easy to miss. Second, separate edit button for topics is an artifact of topics system being developed at a different time, maybe by a different team. Theres really no need to have two separate buttons. The solution? How many edit buttons do we need? I say none. But Where did edit buttons go? You might ask. You see, the nature of description and topics is that its important to get people to fill them when they first create their repo. After that, people rarely change them at all. When there is no description or no topics, we will show a button to add one: And if description/topics are already filled, go to Settings to change them. Problem solved! Problem 8: Files description The traditional Windows File Explorer, together with macOS Finder, have established a simple pattern for file browsing: files on the left, details on the right. Github decided to copy that pattern, but they put a very unexpected thing as details: a message from the last commit when that particular file was changed. Why? I dont know. Commits often touch files for completely arbitrary reasons, so the last commit tells you almost nothing. I cant think of any case when somebody would need that particular information. Maybe they wanted Github to be about git more than about traditional file browsing, and this was the only thing they could think of? Thats my speculation, anyway. The problem with those details is not that such a huge area is filled with something so rarely useful. The problem is that it looks so much like file description it confuses me every time. Tweak layout is not a description of the Docs folder. Need these debug tools too for Toolswhy should I care? That means we can get rid of the descriptions without really losing anything: Problem 9: Repository overview When you get to the repository, the first page you see should not necessarily be Code. We better call it Overviewsomething to get a quick idea of whats going on. Now, the Github repository is more than just a list of files. Its also about how those files change over time. What new features were added? Which bugs were fixed? Were there any new releases recently? All those are as important as the files themselves. Thats why I suggest we add a list of recent commits to the Overview page next to files. You can now see if a project is actively developed, maintained or abandoned, if an issue you care about was recently fixed, if a new version was recently published etc (notice tags and branches pills in commit listI miss this feature on Commits tab SO MUCH). What about that free space on the right? We can put useful stats there: First, I added contributors. Github is all about people and collaboration, thats why they put so much emphasis on Fork and PR buttons. Well, people are the face of that collaboration. They put their free time and energy to make that code happen. Its only fair to see some of their faces. Activity is a relatively new feature that hasnt found its place on repository page yetuntil now. Helps you see how much momentum the project has. Language statistics was unfairly hidden away, now its front and foremost. I also added code size in lines of code an obvious addition that Github still doesnt have for some reason. Altogether, in my opinion, the new Overview tab is more helpful in everyday use. Problem 10: Contextualizing buttons Both Create new file, Upload files and Find files all relate to files, so it will be reasonable to move them right next to the thing they operate on: Files. Github always used to have clone URL directly on a page. That was pretty usefulwhen you needed to grab the code, no additional clicks were required. Unfortunately, during one of the redesigns Github hid the clone URL behind a button. My guess is they did it because there was simply not enough space. But people kept looking for it so they had to paint the button green. Well, after moving file buttons we have enough space to restore full-length Clone link: I also unified all four ways to get the repo into a single control, because semantically they are pretty much the same: a way to get the code on your machine. Last problem: dated look This is how Github used to look back in 2013: And this is a screenshot from 2015: Finally, this is how it looks today: As you can see, the color scheme and main UI elements havent changed much since at least 2013. Its not necessarily bad and mostly proves that the original design was good enough to stand the test of time. But maybe its time to fresh it up a little? Get rid of gradients, dirty washed-out colors, unnecessary separators, add a little more air. Something like this: If you feel disoriented, give it a minute. Once you are used to it, you might notice its actually easier on the eyes and a bit lighter. Finally Current Github design next to my proposal (click to open in a new window): Weve added ~4 more files to the screen of the same vertical size, 6 last commits, 3 branches, 10 contributors faces, project activity AND expanded language stats WITHOUT losing any information. If you know someone at Github, send them a link to this article. Maybe someone there will like my ideas and eventually get to implement themwho knows? Hi! Im Nikita. Here I write about programming and UI design Subscribe I also create open-source stuff: Fira Code, AnyBar, DataScript and Rum. If you like what I do and want to get early access to my articles (along with other benefits), you should support me on Patreon. ",
        "<i>> If you are a programmer, you might be surprised but other people normally don’t like hierarchies. Nested structures are hard to grasp, remember, navigate, and grouping is very often non-intuitive. Nested tabs are one of the worst UI patterns out there.</i><p>GitHub is primarily a development tool, so it should be designed for developers. Hierarchies align very well with development tasks, so it's natural to use them for development tools. That other people don't grasp them is not relevant for GitHub.<p>Also, the three most common navigation tasks I do are \"go to the code\", \"go to the issues\" and \"go to the pull requests.\" Those are also the first three tabs at the top of the hierarchy. I don't think that's an accident; I think the designers at GitHub designed the layout so that the most common tasks are on top and first. In other words, they designed GitHub like a tool, not a normal webpage.<p>With this redesign, I'm going to constantly have to find the \"Issues\" and \"Pull Requests\" tabs among a sea of others. That's not good usability.<p>I've thought that maybe the markdownified README should be flipped up on top, but even that I think is counter-productive. When I'm working with a GitHub project, I commonly want to load up the page and navigate to some files. If not, it's usually not much scrolling to get down to the README. But READMEs can be quite long (which is a good thing), and it would sometimes be a pain to always scroll past them to get to the files. The better solution for that is a good project page.",
        "<i>But maybe it’s time to fresh it up a little? Get rid of gradients, dirty washed-out colors, unnecessary separators, add a little more air.</i><p>No, no, <i>no</i>, <i>NO!!!11</i> I've had it with these \"sea of floating text on an expanse of white\" redesigns, seeing yet another one follow this mindless trend just disgusts me thoroughly. The lines, subtle gradients, and other affordances of the old design serve to organise and direct your eyes into the appropriate sections; without them, everything blends together into a jumbled mess and it almost looks like the stylesheet didn't load fully.<p><i>If you feel disoriented, give it a minute.</i><p>I've had to put up with such redesigns for literally <i>years</i> now (I don't remember when the trend started --- mid 2010s?) and I don't feel them getting any better --- and eventually get around to making a user stylesheet to make them look better than they used to.<p>In contrast to the article this is one of the very few redesigns of a site which I actually would like (not mine, previously discussed at <a href=\"https://news.ycombinator.com/item?id=17242367\" rel=\"nofollow\">https://news.ycombinator.com/item?id=17242367</a>): <a href=\"https://pbs.twimg.com/media/De17PIKXUAE27W6.jpg:large\" rel=\"nofollow\">https://pbs.twimg.com/media/De17PIKXUAE27W6.jpg:large</a><p><i>If you know someone at Github, send them a link to this article. Maybe someone there will like my ideas and eventually get to implement them</i><p>Hopefully not. \"Don't make me get out the custom stylesheet editor...\""
      ],
      "relevant": "true"
    },
    {
      "id": 21007776,
      "title": "Welcoming Semmle to GitHub",
      "search": [
        "Welcoming Semmle to GitHub",
        "Normal",
        "https://github.blog/2019-09-18-github-welcomes-semmle/",
        "Human progress depends on the open source community. One of the biggest issues facing developers today is how to create and consume open source in a secure and trusted way. And at GitHub, we have a unique opportunity and responsibility to provide the tools, best practices, and infrastructure to make software development secure. Today were announcing a big step in securing the open source supply chain: were welcoming Semmle to GitHub. Semmles revolutionary semantic code analysis engine allows developers to write queries that identify code patterns in large codebases and search for vulnerabilities and their variants. Semmle is trusted by security teams at Uber, NASA, Microsoft, Google, and has helped find thousands of vulnerabilities in some of the largest codebases in the world, as well as over 100 CVEs in open source projects to date. Security researchers use Semmle to quickly find vulnerabilities in code with simple declarative queries. These teams then share their queries with the Semmle community to improve the safety of code in other codebases. Software security is a community effort; no single company can find every vulnerability or secure the open source supply chain behind everyones code. Semmles community-driven approach to identifying and preventing security vulnerabilities is the very best way forward. To learn more about our approach to developer security, check out a detailed overview of secure development on GitHub from Shanku Niyogi, SVP of Product. The Semmle blog has many videos and examples of Semmle in action, and you can check out your favorite open source projects on Semmles lgtm.com. Were so excited to be joined by the Semmle team and to welcome their world class engineers and security researchers to GitHub. Together, well bring their work to all open source communities and to our customers. As a community of developers, maintainers, and researchers, we can all work together toward more secure software for everyone. ",
        "The linked blog post [0] and the new security marketing page [1] both have a little more detail on what this actually means.<p>Basically, Semmle offers a static analysis tool that operates on your source code as a graph (from what I understand) and points out bugs and security holes in your code. Github is now offering that for free on repos at all tiers.<p>[0] <a href=\"https://github.blog/2019-09-18-securing-software-together/\" rel=\"nofollow\">https://github.blog/2019-09-18-securing-software-together/</a><p>[1] <a href=\"https://github.com/features/security\" rel=\"nofollow\">https://github.com/features/security</a>",
        "I hate that these kinds of Orwellian phrases \"Welcoming X to the Y Family\" have now become idiomatic of corporate English. Ugh, no. There is no \"family\" involved here, not by any stretch of the word."
      ],
      "relevant": "true"
    },
    {
      "id": 19945984,
      "title": "My Git Workflow (2008)",
      "search": [
        "My Git Workflow (2008)",
        "Normal",
        "https://blog.osteele.com/2008/05/my-git-workflow/",
        "Gits great! But its difficult to learn (it was for me, anyway) especially the index, which unlike the power-user features, comes up in day-to-day operation. Heres my path to enlightenment, and how I ended up using the index in my particular workflow. There are other workflows, but this one is mine. What this isnt: a Git tutorial. It doesnt tell you how to set up git, or use it. I dont cover branches, or merging, or tags, or blobs. There are dozens of really great articles about Git on the web; here are some. Whats here are just some pictures that arent about branches or blobs, that I wished Id been able to look at six months ago when I was trying to figure this stuff out; I still havent seen them elsewhere, so here they are now. My brief history with Git I started using Git about six months ago, in order to productively subcontract for a company that still uses Perforce. Before that I had been a happy Mercurial user; before that, a Darcs devotee; before that, a mildly satisfied Subversion supplicant; and before that, a Perforce proponent. (That last was before the other systems even existed. I introduced Perforce into a couple of companies that had previously been using SourceSafe(!) including the one I was now contracting for.) Each of these systems has flaws. Perforce and Subversion require an always-on connection and make branching (and merging) expensive, and Perforce uses pessimistic locking too (you have to check a file out before you can edit it). I got hit by the exponential merge bug in Darcs (since fixed?); a deeper problem was that I found I wanted to be able to go back in time more often than I needed to commute patches, whereas Darcs makes the latter easy at the expense of the former so Darcs theory of patches, although insightful and beautiful, just didnt match my workflow. Gits problem is its complexity. Half of that is because its actually more powerful than the other systems: its got features that make it look scary but that you can ignore. Another half is that Git uses nonstandard names for about half its most common operations. (The rest of the VCS world has more or less settled on a basic command set, with names such as checkout and revert. Not Git!) And the third half is the index. The index is a mechanism for preventing what you commit from matching what you tested in your working directory. Huh? Git without the index I got through my first four months of Git by pretending it was Subversion. (A faster implementation of Subversion, that works offline, with non-awful branches and merging, that can run as a client to Perforce but still basically Subversion.) The executive summary of this mode of operation is that if you use git commit -a instead of git commit, you can ignore the index altogether. You can alias ci to commit -a (and train yourself not to use the longer commit, which I hadnt been doing anyway), and then you dont have to remember the command-line argument either: $ cat ~/.gitconfig [alias] ci = commit -a co = checkout st = status -a $ git ci -m 'some changes' Adding Back the Index Git keeps copies of your source tree in the locations in this diagram1. (Ill call these locations data stores.) The data store thats new, relative to every other DVCS that I know about, is the index. The one thats new relative to centralized VCSs such as Subversion and Perforce is the local repository. The illustration shows that git add is the only (everyday) operation that can cause the index to diverge from the local repository. The only reason (in Subversion-emulation mode) to use git add is so that git commit will see your changes. The -a option to git commit causes git commit to run git add -u first in which case you never need to run \"git add -u explicitly in which case the index stays in sync with the repository head. This is how the trick in git without the index works: if you always use commit via git commit -a, you can ignore the index2. So whats the point of the index? Is it because Linus likes complicated things? Is to one-up all the other repositories? Is it to increase the complexity of system, so that you have a chance to shoot yourself in the foot if youre not an alpha enough geek? Well, probably. But its good for something else as well. Several things, actually; Ill show you one (that I use), and point you to another. But first, a piece of background that helps in understanding Git. Git isnt at its core a VCS. Its really a distributed versioning file system, down to its own fsck and gc. It was developed as the bottom layer of a VCS, but the VCS layer, which provides the conventional VCS commands (commit, checkout, branch), is more like an uneven veneer than like the porcelain its sometimes called: bits of file system (git core) internals poke through. The disadvantage of this (leaky) layering is that Git is complicated. If you look up how to diff against yesterdays 1pm sources in git diff, it will send you to git rev-parse from the core; if you look up git checkout, you may end up at git-check-ref-format. Most of this you can ignore, but it takes some reading to figure out which. The advantage of the layering is that you can use Git to build your own workflows. Some of these workflows involve the index. Like the other fancy Git features, building your own workflows is something that you can ignore initially, and add when you get to where you need it. This is, historically, how Ive used the index: I ignored it until I was comfortable with more of Git, and now I use it for a more productive workflow than I had with other VCSs. Its not my main reason for using Git, but its turned to a strength from being a liability. Added: By way of illustration, heres how I use Git. Im not recommending this particular workflow; instead, Im hoping that it can further illustrate the relation between the workspace, the index, and the repository; and also the more general idea of using Git to build a workflow. I use the index as a checkpoint. When Im about to make a change that might go awry when I want to explore some direction that Im not sure if I can follow through on or even whether its a good idea, such as a conceptually demanding refactoring or changing a representation type I checkpoint my work into the index. If this is the first change Ive made since my last commit, then I can use the local repository as a checkpoint, but often Ive got one conceptual change that Im implementing as a set of little steps. I want to checkpoint after each step, but save the commit until Ive gotten back to working, tested code. (More on this tomorrow.) Added: This way I can checkpoint every few minutes. Its a very cheap operation, and I dont have to spend time cleaning up the checkpoints later. git diff tells me what Ive changed since the last checkpoint; git diff head shows whats changed since the last commit. git checkout . reverts to the last checkpoint; git checkout head . reverts to the last commit. And git stash and git checkout -m -b operate on the changes since the last commit, which is what I want. Im most efficient when I can fearlessly try out risky changes. Having a test suite is one way to be fearless: the fear of having to step through a set of manual steps to test each changed code path, or worse yet missing some, inhibits creativity. Being able to roll back changes to the last checkpoint eliminates another source of fear. I used to make copies of files before I edited them; my directory would end up littered with files like code.java.1 and code.java.2, which I would periodically sweep away. Having Git handle the checkpoint and diff with them makes all this go faster. (Having painless branches does the same for longer-running experiments, but I dont want to create and then destroy a branch for every five-minute change.) Heres another picture of the same Git commands, this time shown along a second axis, time, proceeding from top to bottom. [This is the behavior diagram to the last pictures dataflow diagram. Kind of.] A number of local edits adds up to something I checkpoint to the index via git add -u; after a while Ive collected something Im ready to commit; and every so many commits I push everything so far to a remote repository, for backup (although Ive got other backup systems), and for sharing. Ive even added another step, releasing a distribution, that goes outside of git. This uses rsync (or scp, or some other build or deployment tool) to upload a tar file (or update a web site, or build a binary to place on a DVD). Some Alternatives Ryan Tomayko has written an excellent essay about a completely different way to use the repository. I recommend it wholeheartedly. Ryans workflow is completely incompatible with mine. Ryan uses the repository to tease apart the changes in his working directory into a sequence of separate commits. I prefer to commit only code that Ive tested in my directory, so Ryans method doesnt work for me. I set pending work aside via git stash or git checkout -m -b when I know I might need to interrupt it with another change; this sounds like it might not work for Ryan. Neither one of these workflows is wrong (and I could easily use Ryans, Im just slightly more efficient with mine); Git supports them both. Theres another way to do this particular task of checkpointing after every few edits, but only persisting some of these checkpoints into the repository. This is to commit each checkpoint to the repository (and go back to ignoring the index at least for checkpointing so this might work with Ryans), and rebase them later. Git lets you squash a number of commits into a single commit before you push it to a public repository (and edit, reorder, and drop un-pushed commits too) thats the rebase -i block in the previous illustration, and you can read about it here. This is a perfectly legitimate mode of operation; its just one that I dont use. Both of these alternatives harken back to Git as being a tool for designing VCS workflows, as much as being a VCS system itself. The reasons I dont use them myself bring us to Commit Policies, which Ill write about tomorrow. ",
        "This is a really well-organized dive into something that, based on the title, I didn't expect to find much value in. I was wrong.<p>Learning git was painful. It felt like an obstacle that periodically stood between me and getting my work done. Gradually, I fell in love with the tool, but until now I never really stopped to think about how my git workflow has evolved. Turns out, it still has room for improvement.",
        "Coming from the simple Subversion way of doing things, instead of using \"add\" you could use \"commit --amend\". This gives you the same workflow as described in the article but without the mental overhead of the index.<p>There is research on this: <a href=\"https://gitless.com/#research\" rel=\"nofollow\">https://gitless.com/#research</a>"
      ],
      "relevant": "true"
    },
    {
      "id": 21403906,
      "title": "GitHub Student Developer Pack",
      "search": [
        "GitHub Student Developer Pack",
        "Normal",
        "https://github.blog/2019-10-30-get-over-100k-worth-of-tools-with-the-github-student-developer-pack/",
        "The GitHub Student Developer Pack now offers over $100k worth of tools and training to every student developer, anywhere that GitHub is available. If youre new to the Pack, it provides verified students with GitHub Pro at no charge while they are in school, plus free access to the best developer tools and trainingthanks to our partnersso they can learn by doing. As the Pack continues to grow and shape the next generation of developers, we continue to listen. Were here to better understand how youre using these tools and whats missing that you hope to see included. Whether youre developing your portfolio, building a new desktop app, or creating an interactive mapthe goal of the Pack is to provide you with the tools you need to be successful. This year, the value of the Pack tripled during the Fall semester by adding nineteen new partners in October plus a dozen in September to the twenty-one who joined our long-time partners for Back-to-School. Lets highlight the partners who joined us since our last post in August. A few words from our new partners We ask all of our new partners what motivated them to join the Pack. Heres a sample of what theyve told us: When I was a student, I actually used the GitHub Student Developer Pack myself! It allowed me to test and learn how to use tools that I wouldnt have been able to otherwise. The Pack was a great help! -Floran Pagliai, Weglot The way that developers learn best is by getting their hands dirty, trying different things, and experimenting with a variety of tools. The Pack allows developers to do that and get exposure creating awesome projects outside the confines of the classroom. -Naeem ul Haq, Educative Not many high school and even college students would ordinarily be able to afford [our tool.] Letting students try it will give us valuable feedback about what up-and-coming developers are looking for. -Levie Rufenacht, Wisej The Pack opens new doors to students that were not accessible before. It basically gives them whats needed to build a project from A to Z, lets them cultivate their curiosity, an essential quality for a developer, and free their creativity. Learning should know no boundaries. -Julien Lehuraux, USE Together Partner details The following are our new partners and the tools and training they are providing, for free, to students: October Appfigures, app store analytics, optimization, and intelligence Astra Security, security suite for your website, including firewall, malware scanner, and a managed bug bounty platform BoltFlare, reliable, secure, and scalable managed WordPress hosting BrowserStack, test your web apps, providing instant access to 2,000+ browsers and real iOS and Android devices Codecov, implement code coverage easier to develop healthier code Educative, level up on trending coding skills at your own pace with interactive, text-based courses EverSQL, boost your database performance by automatically optimizing your SQL queries HazeOver, get focused while working on projects or studying Iconscout, design resources marketplace with high quality icons, illustrations, and stock images Interview Cake, makes coding interviews a piece of cake with practice questions, data structures and algorithms reference pages, cheat sheets, and more Kaltura, build interactive video experiences and advanced media applications MNX.io, managed Cloud hosting for developers NetLicensing, cost-effective and integrated Licensing-as-a-Service (LaaS) solution for your software on any platform from Desktop to IoT and SaaS Scrapinghub, battle-tested cloud platform for running web crawlers where you can manage and automate your web spiders at scale Testmail, unlimited email addresses and mailboxes for automating email tests with powerful APIs Typeform, interactive forms, surveys, and quizzes to engage and grow your audience USE-Together, provides a remote pair programming and team collaboration tool Weglot, make any website multilingual and manage your translations through a single platform Wisej, build powerful web applications in Visual Studio with C# or VB.NET September Blackfire, Code performance measurement tool where you can find and fix bottlenecks Canva, create professional looking graphics and designs, featuring thousands of templates and an easy to use editor Covalence, provides an exclusive developer community and allows you to learn Full Stack web-development with no long-term commitments Crowdin, cloud-based solution that streamlines localization management Education Host, web hosting platform to host assignment and project work GoRails, tutorials for web developers learning Ruby, Rails, Javascript, Turbolinks, Stimulus.js, Vue.js, and more Honeybadger, exception, uptime, and cron monitoring Mailgun, APIs that enable you to send, receive, and track email One Month, learn HTML, CSS, JavaScript and Python in just 30 days Repl.it, an online IDE that lets you instantly code in over fifty languages so you can start learning, building, collaborating, and hosting all in one place Storyscript, top-level, cloud native programming language that helps you orchestrate data flow seamlessly between microservices Vaadin, open source Java framework for building Progressive Web Applications What can I do with the Pack? Looking for ideas for how to use all the new tools? Take a look at these projects or check out GitHub Educations Twitter and Facebook for suggestions. Make a request Have a tool youd like to see included in the Pack? Let the developer know (and tag us) on social media using the hashtag #GitHubPack. Companies interested in including an offer in the Pack can apply to be a partner. Not yet a member of the Pack? Its available for all verified students ages 13+, anywhere in the world where GitHub is available. Join today using your school-issued email, student ID, or other proof of current academic enrollment. Explore the latest offers in the GitHub Student Developer Pack ",
        "For those who are part of Hack Club (<a href=\"https://hackclub.com\" rel=\"nofollow\">https://hackclub.com</a>), we partnered with GitHub to provide speedy access to the Student Developer Pack (48 hrs vs. 2-3 weeks). Redeem at <a href=\"https://hack.af/pack\" rel=\"nofollow\">https://hack.af/pack</a>.<p>More on the partnership at <a href=\"https://medium.com/hackclub/github-hack-club-grants-for-your-club-custom-merch-more-f64d6da0d782\" rel=\"nofollow\">https://medium.com/hackclub/github-hack-club-grants-for-your...</a>",
        "Just a heads up:<p>Do NOT use AWS Educate (regardless if you get it from some hackathon or Github).<p>The amount of pain and suffering you have to go through just to get permission to spin up a EC2 instance is unbearable. Compounded with a ton of restrictions and 60-minute sessions, it'll make you unlike AWS real-quick.<p>I would instead suggest to use the $300 GCP credit (since there's no restrictions for that) if you need cloud credits."
      ],
      "relevant": "true"
    },
    {
      "id": 21289827,
      "title": "My Favourite Git Commit",
      "search": [
        "My Favourite Git Commit",
        "Normal",
        "https://fatbusinessman.com/2019/my-favourite-git-commit",
        "I like Git commit messages. Used well, I think theyre one of the most powerful tools available to document a codebase over its lifetime. Id like to illustrate that by showing you my favourite ever Git commit. This commit is from my time at the Government Digital Service, working on GOV.UK. Its from a developer by the name of Dan Carley, and it has the rather unassuming name of Convert template to US-ASCII to fix error. A quick aside: one of the benefits of coding in the open, as practised at GDS, is that its possible to share examples like this outside the organisation that produced them. Im not sure who first introduced that idea to GDS it was well-established by the time I joined but Im forever grateful to them. Why I like this commit Ive lost count of the number of times Ive shared this as an example of what commit messages can do. Its fun because of the ratio of commit message to code change, but thats not why I think its worth sharing. In a different organisation, from a different developer, this entire commit message might have been change whitespace, or fix bug, or (depending on the teams culture) some less than flattering opinions about the inventor of the non-breaking space. Instead, Dan took the time to craft a really useful commit message for the benefit of those around him. Id like to step through a few of the ways I think this is a really good example. It explains the reason for the change The best commit messages Ive seen dont just explain what theyve changed: they explain why. In this instance: I introduced some tests in a feature branch to match the contents of `/etc/nginx/router_routes.conf`. They worked fine when run with `bundle exec rake spec` or `bundle exec rspec modules/router/spec`. But when run as `bundle exec rake` each should block failed with: ArgumentError: invalid byte sequence in US-ASCII Without this level of detail, we could hazard a guess that this commit fixed some kind of parsing error in some tool or other. Thanks to the commit message, we know exactly which tool it was. This kind of information can be really valuable to document, and is all too easy to lose as people forget the original context behind their work, move on to other teams, and eventually leave the organisation. Its searchable One of the first things in this commit message is the error message that inspired the change: ArgumentError: invalid byte sequence in US-ASCII Anyone else who comes across this error can search through the codebase, either by running git log --grep \"invalid byte sequence\" or by using GitHubs commit search. In fact, from the looks of the search results, multiple people did so, and found out who had found this problem before, when they came across it, and what they did about it. It tells a story This commit message goes into a lot of detail about what the problem looked like, what the process of investigating it looked like, and what the process of fixing it looked like. For example: I eventually found that removing the `.with_content(//)` matchers made the errors go away. That there weren't any weird characters in the spec file. And that it could be reproduced by requiring Puppet in the same interpreter This is one of the areas commit messages can really shine, because theyre documenting the change itself, rather than documenting a particular file, or function, or line of code. This makes them a great place to document this kind of extra information about the journey the codebase has taken. It makes everyone a little smarter One thing Dan did here that I really appreciate was to document the commands he ran at each stage. This can be a great lightweight way to spread knowledge around a team. By reading this commit message, someone can learn quite a few useful tips about the Unix toolset: they can pass an -exec argument into find to run a command against each file found that adding a \\+ onto the end of this command does something interesting (it passes many filenames into a single file command, rather than running the command once per file) file --mime can tell them the MIME type of a file iconv exists The person who reviews this change can learn these things. Anyone who finds this commit later can learn these things. Over enough time and enough commits, this can become a really powerful multiplier for a team. It builds compassion and trust Now the tests work! One hour of my life I won't get back.. This last paragraph adds an extra bit of human context. Reading these words, its hard not to feel just a little bit of Dans frustration at having to spend an hour tracking down a sneaky bug, and satisfaction at fixing it. Now imagine a similar message attached to a short-term hack, or a piece of prototype code that made its way into production and set down roots (as pieces of prototype code love to do). A commit message like this makes it much easier to remember that every change has a human on the other end of it, making the best decision they could given the information they had at the time. Good commits matter Ill admit this is an extreme example, and I wouldnt expect all commits (especially ones of this size) to have this level of detail. Still, I think its an excellent example of explaining the context behind a change, of helping others to learn, and of contributing to the teams collective mental model of the codebase. If youre interested in learning a bit more about the benefits of good commit messages, and some of the tools that make it easier to structure your changes around them, I can recommend: Telling stories through your commits by Joel Chippindale A branch in time by Tekin Sleyman ",
        "I use the following convention to start the subject of commit(posted by someone in a similar HN thread):<p><pre><code>    Add = Create a capability e.g. feature, test, dependency.\n\n    Cut = Remove a capability e.g. feature, test, dependency.\n\n    Fix = Fix an issue e.g. bug, typo, accident, misstatement.\n\n    Bump = Increase the version of something e.g. dependency.\n\n    Make = Change the build process, or tooling, or infra.\n\n    Start = Begin doing something; e.g. create a feature flag.\n\n    Stop = End doing something; e.g. remove a feature flag.\n\n    Refactor = A code change that MUST be just a refactoring.\n\n    Reformat = Refactor of formatting, e.g. omit whitespace.\n\n    Optimize = Refactor of performance, e.g. speed up code.\n\n    Document = Refactor of documentation, e.g. help files.</code></pre>",
        "I really appreciate this kind of commit message. There’s some very good ones in the Mercurial logs too:<p><a href=\"https://www.mercurial-scm.org/repo/hg/rev/3764330f76a6\" rel=\"nofollow\">https://www.mercurial-scm.org/repo/hg/rev/3764330f76a6</a><p><a href=\"https://www.mercurial-scm.org/repo/hg/rev/93486cc46125\" rel=\"nofollow\">https://www.mercurial-scm.org/repo/hg/rev/93486cc46125</a><p><a href=\"https://www.mercurial-scm.org/repo/hg/rev/b7a966ce89ed\" rel=\"nofollow\">https://www.mercurial-scm.org/repo/hg/rev/b7a966ce89ed</a><p><a href=\"https://www.mercurial-scm.org/repo/hg/rev/4a0d0616c47d\" rel=\"nofollow\">https://www.mercurial-scm.org/repo/hg/rev/4a0d0616c47d</a> (all modesty aside)<p>Long commit messages aren’t that atypical. Have a stroll through the logs:<p><a href=\"https://www.mercurial-scm.org/repo/hg/log?style=gitweb\" rel=\"nofollow\">https://www.mercurial-scm.org/repo/hg/log?style=gitweb</a><p>Mercurial inherited this style of commit messages from Linux email-based code review (the Mercurial originator was a kernel hacker), because in that workflow your commit messages are kind of a persuasive essay for why your commit should be accepted. I believe that writing commit messages with that kind of goal in mind, thinking “why should you take this commit?” is a good motivator for writing something good and useful."
      ],
      "relevant": "true"
    },
    {
      "id": 21112632,
      "title": "KDE is adopting GitLab",
      "search": [
        "KDE is adopting GitLab",
        "Normal",
        "https://about.gitlab.com/press/releases/2019-09-17-gitlab-adopted-by-KDE.html",
        "You are here: Press and LogosPress releasesGitLab Adopted by KDE to Foster Open Source Contributions KDE Open Source Community has access to GitLab DevOps platform increasing members software-building options MILAN, ITALY Akademy September 11, 2019 Today GitLab, the DevOps platform delivered as a single application, announced that KDE, an international technology community that creates free and open source software for desktop and portable computing, is adopting GitLab for use by its developers to further enhance infrastructure accessibility and encourage contributions. KDE is a free and open source software community dedicated to creating a user-friendly computing experience. It offers an advanced graphical desktop, a wide variety of applications for communication, work, education and entertainment, and a platform for easily building new applications. Adding access to GitLab will provide the KDE community with additional options for accessible infrastructure for contributors, code review integration with git, streamlined infrastructure and tooling, and an open communication channel with the upstream GitLab community. With the adoption of GitLab, the KDE community, one of the largest Free Software communities with more than 2.600 contributors, will have access to an even wider range of development and code review features with GitLabs DevOps platform to complement current tools used by the KDE community. The KDE community will also be able to integrate GitLabs single application for the DevOps lifecycle to their development workflow, from planning to development and deployment to monitoring. Using GitLab, KDE contributors will have access to Concurrent DevOps, and the ability to manage and secure across stages. GitLab also provides increased visibility and comprehensive governance and accelerates software lifecycles. Were thrilled that the KDE community has chosen to adopt GitLab to offer its developers with additional tooling and features for building cutting-edge applications, said David Planella, Director of Community Relations, GitLab. KDE places a strong emphasis on finding innovative solutions to old and new problems in an atmosphere of open experimentation. This thinking aligns with GitLabs goal of helping teams better collaborate on software development, and we look forward to supporting KDE as they continue to build great software for millions of users across the globe. Lydia Pintscher, President of KDE e.V., said: For an open community like KDE, having friendly, easy-to-use infrastructure is crucial. We have spent the last two years significantly reducing the barriers of entry all across KDE. Moving to GitLab is a major step in that process. Note to editors: During GitLab Commit, GitLabs inaugural user events in Brooklyn on September 17 and London on October 9, KDE will participate in a panel on the benefits of using GitLab with KDE projects. About KDE KDE is an international community that creates Free Software for desktop and portable computing. Among KDE's products are a modern desktop system for Linux and UNIX platforms, and comprehensive office productivity and groupware suites. KDE offers hundreds of software titles in many categories including web applications, multimedia, entertainment, educational, graphics and software development. KDE software is translated into more than 65 languages and is built with ease of use and modern accessibility principles in mind. KDE's full-featured applications run natively on Linux, BSD, Solaris, Windows and macOS. About GitLab GitLab is the DevOps platform built from the ground up as a single application for all stages of the DevOps lifecycle enabling Product, Development, QA, Security, and Operations teams to work concurrently on the same project. GitLab provides a single data store, one user interface, and one permission model across the DevOps lifecycle. This allows teams to significantly reduce cycle times through more efficient collaboration and enhanced focus. Built on Open Source, GitLab works alongside its growing community, which is composed of thousands of developers and millions of users, to continuously deliver new DevOps innovations. GitLab has an estimated 30 million+ users (both Paid and Free) from startups to global enterprises, including Ticketmaster, Jaguar Land Rover, NASDAQ, Dish Network, and Comcast trust GitLab to deliver great software faster. All-remote since 2014, GitLab has more than 1,300 team members in 65 countries. Media Contact Natasha Woods GitLab nwoods@gitlab.com (415) 312-5289 KDE Press Room press@kde.org Git is a trademark of Software Freedom Conservancy and our use of 'GitLab' is under license View page source Edit in Web IDE please contribute. GitLab B.V. ",
        "So far, I am happy only using pure git.<p>If you guys that use GitLab or GitHub or alike would have to switch to pure git - what is the one thing you would miss most?",
        "Couldn't see a link in the post but there seems to be an active GitLab instance here[1]. I've only done a few patches with their previous Phabricator flow and it was a very different experience from the usual GitHub/GitLab workflow. I'm really hoping that switching to something more people have experience with increases the number of contributors.<p>[1]: <a href=\"https://invent.kde.org/public/\" rel=\"nofollow\">https://invent.kde.org/public/</a>"
      ],
      "relevant": "false"
    }
  ]
}
